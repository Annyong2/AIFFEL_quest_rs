{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680f1b13",
   "metadata": {},
   "source": [
    "### <목차>\n",
    " \n",
    "**Step 1. 데이터 수집하기**\n",
    "  - 1.1 라이브러리 가져오기 (불용어 사전NLTK패키지도 함께 가져오기)\n",
    "  - 1.2 Data set 확인\n",
    "\n",
    "**Step 2. 데이터 전처리하기 (추상적 요약)**\n",
    "  - 2.1 중복과 NULL값 정리\n",
    "  - 2.1 중복과 NULL값 정리\n",
    "  - 2.2 불용어 정리 함수 만들기\n",
    "  - 2.3 'text', 'headlines' 컬럼 데이터 전처리하기\n",
    "  - 2.4 샘플 최대 길이 정하기\n",
    "  - 2.5 headlines컬럼 데이터에 SOS, EOS 토큰 붙이기\n",
    "  - 2.6 2.6 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장\n",
    "  - 2.7 test, val 나누기\n",
    "  - 2.8 단어 집합(text, headlines)만들고 요악문 정리(삭제, 패딩)\n",
    "\n",
    "**Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)**\n",
    "  - 3.1 모델 설계하기\n",
    "  - 3.2 모델 훈련하기\n",
    "  - 3.3 학습 결과 시각화 (train loss vs. val loss)\n",
    "  - 3.4 인퍼런스모델 구현하기\n",
    "\n",
    "**Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)**\n",
    "  - 모델 테스트하기\n",
    "\n",
    "**Step 5. Summa을 이용해서 추출적 요약해보기**\n",
    "  - Summa의 summarize를 사용하여 추출적 요약 실행\n",
    "  - 표로 비교하기(추상적 vs. 추출적 요약)\n",
    "\n",
    "\n",
    "회고 :   \n",
    "중간에 어탠션 모델을 설계하는 부분이 빠져서, 모델을 수정하다가 끝까지 못돌린게 아쉽습니다.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ccb875",
   "metadata": {},
   "source": [
    "## **Step 1. 데이터 수집하기**\n",
    "  - text를 본문으로, headline을 summary 데이터로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a470d97",
   "metadata": {},
   "source": [
    "**1.1 라이브러리 가져오기 (불용어 사전NLTK패키지도 함께 가져오기)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e90999f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') # 불용어 사전 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88cb9e",
   "metadata": {},
   "source": [
    "**1.2 Data set 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ceb9c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59229</th>\n",
       "      <td>Cat hair help identify woman who mailed explos...</td>\n",
       "      <td>The person who mailed an improvised explosive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13140</th>\n",
       "      <td>3 children buried alive while digging soil in ...</td>\n",
       "      <td>Three cousins, aged between 10 and 15 years, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18739</th>\n",
       "      <td>Uber driver accused of kicking blind woman out...</td>\n",
       "      <td>A blind woman from Brazil has claimed she was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68902</th>\n",
       "      <td>Lehman Brothers to sell Formula One stake for ...</td>\n",
       "      <td>Bankrupt Lehman Brothers has announced the sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34235</th>\n",
       "      <td>Middle East Uber rival Careem reveals 14M user...</td>\n",
       "      <td>Uber rival Careem, a ride-hail startup based i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86996</th>\n",
       "      <td>1 killed, 5 injured in military plane crash in...</td>\n",
       "      <td>A Russian serviceman was killed and five other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61155</th>\n",
       "      <td>Telangana cop suspended over massage from fema...</td>\n",
       "      <td>Assistant Sub-Inspector Hasan from Telangana's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91401</th>\n",
       "      <td>Sourav Ganguly denies creating Dhoni-less IPL ...</td>\n",
       "      <td>Former India captain Sourav Ganguly has denied...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24432</th>\n",
       "      <td>Petition asks Disney to hire director fired fo...</td>\n",
       "      <td>Over 2 lakh people have signed a petition, add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83777</th>\n",
       "      <td>No evidence of any irregularities in Panaya de...</td>\n",
       "      <td>Infosys on Friday said its internal audit comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "59229  Cat hair help identify woman who mailed explos...   \n",
       "13140  3 children buried alive while digging soil in ...   \n",
       "18739  Uber driver accused of kicking blind woman out...   \n",
       "68902  Lehman Brothers to sell Formula One stake for ...   \n",
       "34235  Middle East Uber rival Careem reveals 14M user...   \n",
       "86996  1 killed, 5 injured in military plane crash in...   \n",
       "61155  Telangana cop suspended over massage from fema...   \n",
       "91401  Sourav Ganguly denies creating Dhoni-less IPL ...   \n",
       "24432  Petition asks Disney to hire director fired fo...   \n",
       "83777  No evidence of any irregularities in Panaya de...   \n",
       "\n",
       "                                                    text  \n",
       "59229  The person who mailed an improvised explosive ...  \n",
       "13140  Three cousins, aged between 10 and 15 years, w...  \n",
       "18739  A blind woman from Brazil has claimed she was ...  \n",
       "68902  Bankrupt Lehman Brothers has announced the sal...  \n",
       "34235  Uber rival Careem, a ride-hail startup based i...  \n",
       "86996  A Russian serviceman was killed and five other...  \n",
       "61155  Assistant Sub-Inspector Hasan from Telangana's...  \n",
       "91401  Former India captain Sourav Ganguly has denied...  \n",
       "24432  Over 2 lakh people have signed a petition, add...  \n",
       "83777  Infosys on Friday said its internal audit comm...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/AIFFEL_quest_rs/AIFFEL_quest_rs/Exploration/Ex06/news_summary_more.csv\", nrows=100000)\n",
    "data_org = data.copy()\n",
    "print('전체 샘플수 :', (len(data_org)))\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab98e4d",
   "metadata": {},
   "source": [
    "## **Step 2. 데이터 전처리하기 (추상적 요약)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59d718",
   "metadata": {},
   "source": [
    "**2.1 중복과 NULL값 정리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04013a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수(중복값정리 전) : 98401\n",
      "전체 샘플수(중복값정리 후) : 98360\n"
     ]
    }
   ],
   "source": [
    "# 중복값 정리\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수(중복값정리 전) :', (len(data_org)))\n",
    "print('전체 샘플수(중복값정리 후) :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4789e14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n",
      "\n",
      " => NULL정리할 것이 없음을 확인함\n"
     ]
    }
   ],
   "source": [
    "# NULL 값 정리\n",
    "print(data.isnull().sum())\n",
    "print('\\n', '=> NULL정리할 것이 없음을 확인함')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c638e460",
   "metadata": {},
   "source": [
    "**2.2 불용어 정리 함수 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7de702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n",
      "불용어 개수 : 179\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "# print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e6d4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17a857a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n",
      "summary: great way start day\n"
     ]
    }
   ],
   "source": [
    "# 함수 잘 만들어졌나 확인\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다.\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, True))   # 불용어를 제거합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d82cf",
   "metadata": {},
   "source": [
    "**2.3 'text', 'headlines' 컬럼 데이터 전처리하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d1617da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "# 전체 text 데이터에 대한 전처리 \n",
    "clean_text = []\n",
    "\n",
    "# 반복문으로 사용자정의 함수 사용하여 불용어 제거하기\n",
    "for x in data['text']:\n",
    "    clean_text.append(preprocess_sentence(x))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85011191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "# 전체 headlines 데이터에 대한 전처리  \n",
    "clean_summary = []\n",
    "\n",
    "# 반복문으로 사용자정의 함수 사용하여 불용어 제거하기\n",
    "for y in data['headlines']:\n",
    "    clean_summary.append(preprocess_sentence(y,False))\n",
    "    \n",
    "# 전처리 후 출력\n",
    "print(\"Headlines 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2399d",
   "metadata": {},
   "source": [
    "**(혹시나 있을 빈 값을 NULL로 변환)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82541a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "add36d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0e2cf",
   "metadata": {},
   "source": [
    "**2.4 샘플 최대 길이 정하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b4749440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a3ba4",
   "metadata": {},
   "source": [
    "2.4.1 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bdad0d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAet0lEQVR4nO3de7xXdZ3v8dc7ULNEwSAGuQQmXdBJsq3SyRoviahN2IyZVkpm0UVTO9aE1UmznOg0aWMXC4OgMsnjJRmlkGOo45RyUZKLedwJBoSXRAFzQsHP+WN9dyx//PZm7cX+3dzv5+OxHnv9Puv2+aGbD9/1/a7vUkRgZmZWxssanYCZmbUuFxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxKzBJN0u6SNp/UOS7spte0bS/o3LzqxrLiJmVUhaLemdFbEX/QVfDxGxV0Q8XM9rmnWHi4iZmZXmImJWgqT9JF0v6QlJqySdm9t2mKTfSnpa0npJ35G0e277sZJ+L2mjpO8A6uI6IemAtD5T0ncl3SJps6R7JL02t+8bJM2XtEHSg5JOyW07QdLKdNw6SZ/p8T8U65VcRMy6SdLLgP8AfgcMBY4Bzpd0XNplG/BpYCDw1rT9k+nYgcANwBfT9j8Ab+vG5U8FvgwMANqBS9N5XwnMB34GvDrt9z1JY9Jx04GPRUQ/4CDg19393mbVuIiYde4XqTXxtKSnge+l+KHAoIi4JCKeS30WV5H9xU1ELImIuyNia0SsBn4A/EM69gRgRURcFxHPA98CHu1GTjdGxMKI2ApcDYxN8XcBqyPiR+m69wHXA+9N258HxkjaOyKeioh7u/uHYVaNi4hZ506KiP4dC6k1AbwG2K+iwHweGAwg6XWSbpb0qKRNwL+StToA9gPWdFwgshlQ//a5gHzBeRbYK5fT4RU5fQD4u7T9n8kK2COS7pD01m5c06xTfRudgFkLWgOsiojRnWy/ErgPOC0iNks6Hzg5bVsPDO/YUZLyn3cxpzsi4thqGyNiETBR0m7AOcC1PXRd6+XcEjHrvoXAZkmfk7SnpD6SDpJ0aNreD9gEPCPpDcAncsfeAhwo6Z8k9QXOZXtrYVfcDLxO0umSdkvLoZLeKGl3SR+QtE+6hbYJeKEHrmnmImLWXRGxjawPYiywCvgz8ENgn7TLZ4D3A5vJ+kp+njv2z2T9FFOBJ4HRwH/1QE6bgfFk/TJ/Irvt9XVgj7TL6cDqdHvt42S3usx2mfxSKjMzK8stETMzK81FxMzMSqtZEZH0ckkLJf1O0gpJX07xUelJ23ZJP+94klfSHulze9o+MneuC1P8wdwDXUiakGLtkqbU6ruYmVl1tWyJbAGOjoiDyTogJ0gaR9bZd3lEHAA8BZyV9j8LeCrFL0/7kZ64PRU4EJhA9hRuH0l9gO8CxwNjgNNyT+eamVkd1Ow5kfQQ1TPp425pCeBospErALOAi8nG1U9M6wDXAd9JY+gnArMjYguwSlI7cFjar71jhlNJs9O+K7vKa+DAgTFy5Mhd/HZmZr3LkiVL/hwRgyrjNX3YMLUWlgAHkLUa/gA8naZsAFhLNvcQ6ecagIjYKmkj8KoUvzt32vwxayrih3eSx2RgMsCIESNYvHjxrn0xM7NeRtIj1eI17ViPiG0RMRYYRtZ6eEMtr9dFHtMioi0i2gYN2qGQmplZSXUZnRURTwMLyGY07Z+e1IWsuKxL6+tI0zCk7fuQPYz1t3jFMZ3FzcysTmo5OmuQpP5pfU/gWOABsmLSMY/QJOCmtD4nfSZt/3XqV5kDnJpGb40ie8J3IbAIGJ1Ge+1O1vk+p1bfx8zMdlTLPpEhwKzUL/Iy4NqIuFnSSmC2pK+STVI3Pe0/HfhJ6jjfwPZptVdIupasw3wrcHaadgJJ5wDzgD7AjIhYUcPvY2ZmFXrdtCdtbW3hjnUzs+6RtCQi2irjfmLdzMxKcxExM7PSXETMzKw0FxEzMyvNr8c1axEjp9zS6bbVU0+sYyZm27klYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWk1KyKShktaIGmlpBWSzkvxiyWtk7Q0LSfkjrlQUrukByUdl4tPSLF2SVNy8VGS7knxn0vavVbfx8zMdlTLlshW4IKIGAOMA86WNCZtuzwixqZlLkDadipwIDAB+J6kPpL6AN8FjgfGAKflzvP1dK4DgKeAs2r4fczMrELNikhErI+Ie9P6ZuABYGgXh0wEZkfElohYBbQDh6WlPSIejojngNnAREkCjgauS8fPAk6qyZcxM7Oq6tInImkk8GbgnhQ6R9L9kmZIGpBiQ4E1ucPWplhn8VcBT0fE1op4tetPlrRY0uInnniiJ76SmZlRhyIiaS/geuD8iNgEXAm8FhgLrAe+WescImJaRLRFRNugQYNqfTkzs16jby1PLmk3sgJydUTcABARj+W2XwXcnD6uA4bnDh+WYnQSfxLoL6lvao3k9zczszqoWRFJfRbTgQci4rJcfEhErE8f3wMsT+tzgJ9JugzYDxgNLAQEjJY0iqxInAq8PyJC0gLgZLJ+kknATbX6PmYvZSOn3NLpttVTT6xjJtZqatkSeRtwOrBM0tIU+zzZ6KqxQACrgY8BRMQKSdcCK8lGdp0dEdsAJJ0DzAP6ADMiYkU63+eA2ZK+CtxHVrTMzKxOalZEIuIuslZEpbldHHMpcGmV+Nxqx0XEw2Sjt8zMrAH8xLqZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZW2k6LiKT3SuqX1r8o6QZJh9Q+NTMza3ZFWiL/KyI2SzoCeCcwHbiytmmZmVkrKFJEtqWfJwLTIuIWYPfapWRmZq2iSBFZJ+kHwPuAuZL2KHicmZm9xBUpBqcA84DjIuJpYF/gs7VMyszMWsNOi0hEPAs8DhyRQluBh2qZlJmZtYYio7MuAj4HXJhCuwE/rWVSZmbWGorcznoP8G7gLwAR8Seg384OkjRc0gJJKyWtkHReiu8rab6kh9LPASkuSVdIapd0f34YsaRJaf+HJE3Kxd8iaVk65gpJ6t7XNzOzXVGkiDwXEQEEgKRXFjz3VuCCiBgDjAPOljQGmALcFhGjgdvSZ4DjgdFpmUwaRixpX+Ai4HDgMOCijsKT9vlo7rgJBXMzM7MeUKSIXJtGZ/WX9FHg/wJX7eygiFgfEfem9c3AA8BQYCIwK+02CzgprU8EfhyZu9P1hgDHAfMjYkNEPAXMByakbXtHxN2pyP04dy4zM6uDvjvbISL+TdKxwCbg9cCXImJ+dy4iaSTwZuAeYHBErE+bHgUGp/WhwJrcYWtTrKv42irxatefTNa6YcSIEd1J3czMurDTIgKQika3CkcHSXsB1wPnR8SmfLdFRISkKHPe7oiIacA0gLa2tppfz8yst+j0dpakzZI2VVk2S9pU5OSSdiMrIFdHxA0p/Fi6FUX6+XiKrwOG5w4flmJdxYdViZuZWZ10WkQiol9E7F1l6RcRe+/sxGmk1HTggYi4LLdpDtAxwmoScFMufkYapTUO2Jhue80DxksakDrUxwPz0rZNksala52RO5eZmdVBodtZabjtEWQjtO6KiPsKHPY24HRgmaSlKfZ5YCpZZ/1ZwCNkT8QDzAVOANqBZ4EzASJig6SvAIvSfpdExIa0/klgJrAn8Mu0mJlZney0iEj6EvBeoON21ExJ/ycivtrVcRFxF9DZcxvHVNk/gLM7OdcMYEaV+GLgoK7yMDOz2inSEvkAcHBE/BVA0lRgKdBlETEzs5e+Is+J/Al4ee7zHrgD28zMKNYS2QiskDSfrE/kWGChpCsAIuLcGuZnZmZNrEgRuTEtHW6vTSpmZtZqijyxPmtn+5iZWe9UZCr4d0m6T9KG7j5saGZmL21Fbmd9C/gnYFkahmtmnRg55ZZOt62eemIdMzGrjyKjs9YAy11AzMysUpGWyL8AcyXdAWzpCFZMZWJmZr1QkSJyKfAM2bMiu9c2HTMzayVFish+EeGpRczMbAdF+kTmShpf80zMzKzlFCkinwB+Jem/PcTXzMzyijxs2K8eiZiZWesp+j6RAcBochMxRsSdtUrKzMxaQ5H3iXwEOI/s9bNLgXHAb4Gja5qZmZk1vSJ9IucBhwKPRMRRwJuBp2uZlJmZtYYiReSvuRdS7RERvwdeX9u0zMysFRTpE1krqT/wC2C+pKfI3o1uZma9XJHRWe9JqxdLWgDsA/yqplmZmVlLKDIV/Gsl7dHxERgJvKKWSZmZWWso0idyPbBN0gHANGA48LOaZmVmZi2hSBF5ISK2Au8Bvh0RnwWG1DYtMzNrBUWKyPOSTgMmATen2G61S8nMzFpFkSJyJvBW4NKIWCVpFPCT2qZlZmatoMjorJXAubnPq4Cv1zIpMzNrDUVaImZmZlXVrIhImiHpcUnLc7GLJa2TtDQtJ+S2XSipXdKDko7LxSekWLukKbn4KEn3pPjPJfmti2ZmddZpEZH0k/TzvJLnnglMqBK/PCLGpmVuusYY4FTgwHTM9yT1kdQH+C5wPDAGOC3tC9kttcsj4gDgKeCsknmamVlJXbVE3iJpP+DDkgZI2je/7OzEaar4DQXzmAjMjogtqc+lHTgsLe0R8XBEPAfMBiZKEtkswtel42cBJxW8lpmZ9ZCuOta/D9wG7A8sIXtavUOkeBnnSDoDWAxcEBFPAUOBu3P7rE0xgDUV8cOBVwFPp+dXKvffgaTJwGSAESNGlEzbzMwqddoSiYgrIuKNwIyI2D8iRuWWsgXkSuC1wFhgPfDNkufploiYFhFtEdE2aNCgelzSzKxXKDLE9xOSDgbenkJ3RsT9ZS4WEY91rEu6iu0PL64jm06lw7AUo5P4k0B/SX1TayS/v5mZ1UmRCRjPBa4GXp2WqyV9qszFJOWnS3kP0DFyaw5wqqQ90sOMo4GFwCJgdBqJtTtZ5/uciAhgAXByOn4ScFOZnMzMrLwi7xP5CHB4RPwFQNLXyV6P++2uDpJ0DXAkMFDSWuAi4EhJY8n6VFYDHwOIiBWSrgVWAluBsyNiWzrPOcA8oA/ZrbUV6RKfA2ZL+ipwHzC92Fc2M7OeUqSICNiW+7yNF3eyVxURp1UJd/oXfURcClxaJT4XmFsl/jDZ6C0zM2uQIkXkR8A9km5Mn0/C/+o3MzOKdaxfJul24IgUOjMi7qtpVmZm1hKKtESIiHuBe2uci5mZtRhPwGhmZqW5iJiZWWldFpE0CeKCeiVjZmatpcsikp7VeEHSPnXKx8zMWkiRjvVngGWS5gN/6QhGxLmdH2JmZr1BkSJyQ1rMzMxepMhzIrMk7QmMiIgH65CTmZm1iCITMP4jsBT4Vfo8VtKcGudlZmYtoMjtrIvJ5qi6HSAilkoq+z4RM3uJGTnllk63rZ56Yh0zsUYo8pzI8xGxsSL2Qi2SMTOz1lKkJbJC0vuBPpJGA+cCv6ltWmZm1gqKtEQ+BRwIbAGuATYB59cwJzMzaxFFRmc9C3whvYwqImJz7dMyM7NWUGR01qGSlgH3kz10+DtJb6l9amZm1uyK9IlMBz4ZEf8JIOkIshdVvamWiZmZWfMr0ieyraOAAETEXWTvQTczs16u05aIpEPS6h2SfkDWqR7A+0jPjJiZWe/W1e2sb1Z8vii3HjXIxczMWkynRSQijqpnImZm1np22rEuqT9wBjAyv7+ngjczsyKjs+YCdwPL8HQnZmaWU6SIvDwi/mfNMzEzs5ZTZIjvTyR9VNIQSft2LDXPzMzMml6RlshzwDeAL7B9VFYAng7ezKyXK9ISuQA4ICJGRsSotOy0gEiaIelxSctzsX0lzZf0UPo5IMUl6QpJ7ZLuzz2jgqRJaf+HJE3Kxd8iaVk65gpJ6t5XNzOzXVWkiLQDz5Y490xgQkVsCnBbRIwGbkufAY4HRqdlMnAlZEWH7PmUw8lejHVRR+FJ+3w0d1zltczMrMaK3M76C7BU0gKy6eCBnQ/xjYg7JY2sCE8Ejkzrs8iefP9civ84IgK4W1J/SUPSvvMjYgOApPnABEm3A3tHxN0p/mPgJOCXBb6PmZn1kCJF5Bdp6QmDI2J9Wn8UGJzWhwJrcvutTbGu4murxKuSNJmshcOIESN2IX0zM8sr8j6RWbW4cESEpLpMnxIR04BpAG1tbZ6yxcyshxR5Yn0VVebKKtK5XsVjkoZExPp0u+rxFF8HDM/tNyzF1rH99ldH/PYUH1ZlfzMzq6MiHettwKFpeTtwBfDTktebA3SMsJoE3JSLn5FGaY0DNqbbXvOA8ZIGpA718cC8tG2TpHFpVNYZuXOZmVmdFLmd9WRF6FuSlgBf6uo4SdeQtSIGSlpLNspqKnCtpLOAR4BT0u5zgRPYPhLszHTtDZK+AixK+13S0ckOfJJsBNieZB3q7lQ3M6uzIrezDsl9fBlZy6RI8Tmtk03HVNk3gLM7Oc8MYEaV+GLgoJ3lYWZmtVNkdFb+vSJbgdVsb0GYmVkvVqRF4feKmJlZVUVuZ+0B/DM7vk/kktqlZWZmraDI7aybgI3AEnJPrJuZmRUpIsMiwvNSmZnZDoo8J/IbSX9f80zMzKzlFGmJHAF8KD25vgUQ2ajcN9U0MzMza3pFisjxNc/CzMxaUpEhvo/UIxEzM2s9RfpEzMzMqnIRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEorMu2JWa8ycsotnW5bPfXEOmZi1vzcEjEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKa0gRkbRa0jJJSyUtTrF9Jc2X9FD6OSDFJekKSe2S7pd0SO48k9L+D0ma1IjvYmbWmzWyJXJURIyNiLb0eQpwW0SMBm5LnwGOB0anZTJwJWRFB7gIOBw4DLioo/CYmVl9NNPtrInArLQ+CzgpF/9xZO4G+ksaAhwHzI+IDRHxFDAfmFDnnM3MerVGFZEAbpW0RNLkFBscEevT+qPA4LQ+FFiTO3ZtinUWNzOzOmnUBIxHRMQ6Sa8G5kv6fX5jRISk6KmLpUI1GWDEiBE9dVozs16vIS2RiFiXfj4O3EjWp/FYuk1F+vl42n0dMDx3+LAU6yxe7XrTIqItItoGDRrUk1/FzKxXq3sRkfRKSf061oHxwHJgDtAxwmoScFNanwOckUZpjQM2ptte84DxkgakDvXxKWZmZnXSiNtZg4EbJXVc/2cR8StJi4BrJZ0FPAKckvafC5wAtAPPAmcCRMQGSV8BFqX9LomIDfX7GmZmVvciEhEPAwdXiT8JHFMlHsDZnZxrBjCjp3M0M7Ni/GZDM2tafstk82um50TMzKzFuIiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWl+Pa61JL821aw5uCViZmaluYiYmVlpLiJmZlaai4iZmZXmjnUz63W6GpgBHpzRHW6JmJlZaS4iZmZWmouImZmV1vJFRNIESQ9Kapc0pdH5mJn1Ji3dsS6pD/Bd4FhgLbBI0pyIWNnYzAzceWnWG7R0EQEOA9oj4mEASbOBiYCLiJnVjKfd2U4R0egcSpN0MjAhIj6SPp8OHB4R51TsNxmYnD6+Hniwrol2biDw50YnsRPNnmOz5wfOsSc0e37Q/Dnuan6viYhBlcFWb4kUEhHTgGmNzqOSpMUR0dboPLrS7Dk2e37gHHtCs+cHzZ9jrfJr9Y71dcDw3OdhKWZmZnXQ6kVkETBa0ihJuwOnAnManJOZWa/R0rezImKrpHOAeUAfYEZErGhwWt3RdLfYqmj2HJs9P3COPaHZ84Pmz7Em+bV0x7qZmTVWq9/OMjOzBnIRMTOz0lxEGkDScEkLJK2UtELSeY3OqRpJfSTdJ+nmRudSjaT+kq6T9HtJD0h6a6NzypP06fTfd7mkayS9vAlymiHpcUnLc7F9Jc2X9FD6OaAJc/xG+u98v6QbJfVvYIpVc8xtu0BSSBrYiNxSDlXzk/Sp9Oe4QtL/7olruYg0xlbggogYA4wDzpY0psE5VXMe8ECjk+jCvwO/iog3AAfTRLlKGgqcC7RFxEFkAz9ObWxWAMwEJlTEpgC3RcRo4Lb0uZFmsmOO84GDIuJNwP8DLqx3UhVmsmOOSBoOjAf+WO+EKsykIj9JR5HN6HFwRBwI/FtPXMhFpAEiYn1E3JvWN5P95Te0sVm9mKRhwInADxudSzWS9gHeAUwHiIjnIuLphia1o77AnpL6Aq8A/tTgfIiIO4ENFeGJwKy0Pgs4qZ45VaqWY0TcGhFb08e7yZ4Ja5hO/hwBLgf+BWjoiKVO8vsEMDUitqR9Hu+Ja7mINJikkcCbgXsanEqlb5H9MrzQ4Dw6Mwp4AvhRuuX2Q0mvbHRSHSJiHdm/9P4IrAc2RsStjc2qU4MjYn1afxQY3MhkCvgw8MtGJ1FJ0kRgXUT8rtG5dOJ1wNsl3SPpDkmH9sRJXUQaSNJewPXA+RGxqdH5dJD0LuDxiFjS6Fy60Bc4BLgyIt4M/IXG34b5m9SvMJGs2O0HvFLSBxub1c5FNua/acf9S/oC2e3gqxudS56kVwCfB77U6Fy60BfYl+wW+meBayVpV0/qItIgknYjKyBXR8QNjc6nwtuAd0taDcwGjpb008amtIO1wNqI6GjBXUdWVJrFO4FVEfFERDwP3AD8jwbn1JnHJA0BSD975DZHT5P0IeBdwAei+R5wey3ZPxh+l35vhgH3Svq7hmb1YmuBGyKzkOwuwy53/ruINECq/tOBByLiskbnUykiLoyIYRExkqwz+NcR0VT/io6IR4E1kl6fQsfQXK8A+CMwTtIr0n/vY2iijv8Kc4BJaX0ScFMDc6lK0gSy26vvjohnG51PpYhYFhGvjoiR6fdmLXBI+v+0WfwCOApA0uuA3emBWYddRBrjbcDpZP/CX5qWExqdVAv6FHC1pPuBscC/Njad7VIL6TrgXmAZ2e9aw6fFkHQN8Fvg9ZLWSjoLmAocK+khshbU1CbM8TtAP2B++n35fhPm2DQ6yW8GsH8a9jsbmNQTLTpPe2JmZqW5JWJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmI2EuWpGdqcM6x+eHYki6W9JldON970wzEC3omw9J5rG7krLPWulxEzLpnLNCTz/ScBXw0Io7qwXOa1Y2LiPUKkj4raVF6H8WXU2xkagVcld6vcKukPdO2Q9O+S9O7LJZL2h24BHhfir8vnX6MpNslPSzp3E6uf5qkZek8X0+xLwFHANMlfaNi/yGS7kzXWS7p7Sl+paTFKd8v5/ZfLelraf/Fkg6RNE/SHyR9PO1zZDrnLZIelPR9STv8HSDpg5IWpnP9QNl7ZfpImplyWSbp07v4n8ReKiLCi5eX5AI8k36OJ3taXGT/cLqZbBr5kWST+Y1N+10LfDCtLwfemtanAsvT+oeA7+SucTHwG2APsnmIngR2q8hjP7JpUAaRTYL3a+CktO12sneOVOZ+AfCFtN4H6JfW983FbgfelD6vBj6R1i8H7id7wnsQ8FiKHwn8Fdg/HT8fODl3/EDgjcB/dHwH4HvAGcBbgPm5/Po3+r+vl+ZY3BKx3mB8Wu4jm4bkDcDotG1VRCxN60uAkcremtcvIn6b4j/byflviYgtEfFnsskLK6dSPxS4PbLJGDtmoH3HTs65CDhT0sXA30f23hmAUyTdm77LgUD+ZWZz0s9lwD0RsTkingC2aPubABdGxMMRsQ24hqwllHcMWcFYJGlp+rw/8DDZlBnfTvNYNc2s09ZYfRudgFkdCPhaRPzgRcHsXS5bcqFtwJ4lzl95jl3+vYqIOyW9g+zFYDMlXQb8J/AZ4NCIeErSTCD/yt2OPF6oyOmFXE6V8xxVfhYwKyJ2eHOgpIOB44CPA6eQvdfDejm3RKw3mAd8OL2/BUlDJb26s50je0PiZkmHp1D+tbabyW4TdcdC4B8kDZTUBzgNuKOrAyS9huw21FVkb5c8BNib7L0pGyUNBo7vZh4Ah0kalfpC3gfcVbH9NuDkjj8fZe9ff00aufWyiLge+CLNNe2+NZBbIvaSFxG3Snoj8NtsVnaeAT5I1mrozFnAVZJeIPsLf2OKLwCmpFs9Xyt4/fWSpqRjRXb7a2fTrR8JfFbS8ynfMyJilaT7gN8Da4D/KnL9CovIZsQ9IOVzY0WuKyV9Ebg1FZrngbOB/yZ7i2THPzwb/Y5zaxKexdesCkl7RcQzaX0KMCQizmtwWrtE0pHAZyLiXQ1OxV5C3BIxq+5ESReS/Y48QjYqy8wquCViZmaluWPdzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEr7/995MFNi6UacAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96363b8f",
   "metadata": {},
   "source": [
    "**2.4.3 최대값 정하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00cd5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 12 # 11, 10 , 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "62b16661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64181219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below_threshold_len(text_max_len, data['text'])\n",
    "# below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4d2c0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998576657177715\n",
      "전체 샘플 중 길이가 12 이하인 샘플의 비율: 0.9880337535583571\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(summary_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a41ca285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 샘플수 : 98401\n",
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "filtered_data = data[\n",
    "        data.apply(lambda x: len(x['text'].split()) <= text_max_len and len(x['headlines'].split()) <= summary_max_len, axis=1)\n",
    "    ]\n",
    "\n",
    "\n",
    "print('원본 샘플수 :', (len(data_org)))\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa4e16",
   "metadata": {},
   "source": [
    "**2.5 headlines컬럼 데이터에 SOS, EOS 토큰 붙이기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48cc2e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e36ea",
   "metadata": {},
   "source": [
    "**2.6 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "439c50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f29b91",
   "metadata": {},
   "source": [
    "**2.7 test, val 나누기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49256719",
   "metadata": {},
   "source": [
    "encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b00fda7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29704 29320 28640 ... 32004 11776 19627]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "13ebe6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47bdbf",
   "metadata": {},
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주면 잘 섞인 샘플을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "23c0f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 수 : 49180\n",
      "검증 데이터의 수 : 29508\n",
      "테스트 데이터의 수 : 19672\n",
      "98360\n"
     ]
    }
   ],
   "source": [
    "# TRAIN, VAL, TEST\n",
    "n_of_trn = int(len(encoder_input)*0.5)\n",
    "n_of_val = int(len(encoder_input)*0.3)\n",
    "n_of_tst = int(len(encoder_input)*0.2)\n",
    "\n",
    "print('훈련 데이터의 수 :', n_of_trn)\n",
    "print('검증 데이터의 수 :', n_of_val)\n",
    "print('테스트 데이터의 수 :', n_of_tst)\n",
    "print(n_of_trn+n_of_val+n_of_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa929fd3",
   "metadata": {},
   "source": [
    "위에 나눈 비율 (5:3:2)로 TRAIN, VAL, TEST 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f553b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN 데이터 나누기\n",
    "encoder_input_train = encoder_input[0:49180]\n",
    "decoder_input_train = decoder_input[0:49180]\n",
    "decoder_target_train = decoder_target[0:49180]\n",
    "# VAL\n",
    "encoder_input_val= encoder_input[49180:78688]\n",
    "decoder_input_val= decoder_input[49180:78688]\n",
    "decoder_target_val = decoder_target[49180:78688]\n",
    "# TEST \n",
    "encoder_input_test = encoder_input[78688:]\n",
    "decoder_input_test = decoder_input[78688:]\n",
    "decoder_target_test = decoder_target[78688:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "53462cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 49180\n",
      "훈련 레이블의 개수 : 49180\n",
      "검증 데이터의 개수 : 29508\n",
      "검증 레이블의 개수 : 29508\n",
      "테스트 데이터의 개수 : 19672\n",
      "테스트 레이블의 개수 : 19672\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "\n",
    "print('검증 데이터의 개수 :', len(encoder_input_val))\n",
    "print('검증 레이블의 개수 :', len(decoder_input_val))\n",
    "\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fbcd99",
   "metadata": {},
   "source": [
    "**2.8 단어 집합 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5aa4cd",
   "metadata": {},
   "source": [
    "**2.8.1 단어 집합 : text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1c87071",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b74c041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 57387\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 36074\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 21313\n",
      "단어 집합에서 희귀 단어의 비율: 62.860926690713924\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.5769288264516823\n"
     ]
    }
   ],
   "source": [
    "threshold = 5\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5173a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67758a",
   "metadata": {},
   "source": [
    "등장 빈도가 5회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. 위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5326a597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22, 715, 1196, 14, 688, 1719, 149, 14, 6953, 233, 542, 599, 985, 2723, 1093, 1222, 899, 233, 599, 273, 2724, 105, 6953, 888, 1719, 7246, 1093, 1222, 1139, 2516, 151, 14], [49, 110, 43, 89, 3114, 3451, 5290, 2, 7, 1402, 1744, 2310, 543, 828, 579, 18, 625, 5290, 2015, 1291, 968, 4627, 262, 1340, 35, 175, 19, 257, 310, 230, 5290, 115, 209, 184, 4361], [361, 249, 193, 698, 452, 6573, 5136, 62, 689, 798, 1057, 1325, 2501, 1, 280, 658, 2411, 39, 145, 1193, 5447, 802, 3186, 689, 37, 6107, 3515, 3611, 2993, 1, 1135, 1164, 768]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_val = src_tokenizer.texts_to_sequences(encoder_input_val)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04876c1",
   "metadata": {},
   "source": [
    "**2.8.2 단어 집합 : headlines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d638e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train) # headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8fffe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 25424\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 16358\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9066\n",
      "단어 집합에서 희귀 단어의 비율: 64.34078036500944\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.505414806129016\n"
     ]
    }
   ],
   "source": [
    "threshold = 5\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d06df411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tar_vocab = 2000\\ntar_tokenizer = Tokenizer(num_words=tar_vocab) \\ntar_tokenizer.fit_on_texts(decoder_input_train)\\n\\ntar_tokenizer.fit_on_texts(decoder_target_train)\\n\\n# 텍스트 시퀀스를 정수 시퀀스로 변환\\ndecoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \\ndecoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\\n\\ndecoder_input_val = tar_tokenizer.texts_to_sequences(decoder_input_val)\\ndecoder_target_val = tar_tokenizer.texts_to_sequences(decoder_target_val)\\n\\ndecoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\\ndecoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "\n",
    "decoder_input_val = tar_tokenizer.texts_to_sequences(decoder_input_val)\n",
    "decoder_target_val = tar_tokenizer.texts_to_sequences(decoder_target_val)\n",
    "\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0f8c31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "\n",
    "decoder_input_val = tar_tokenizer.texts_to_sequences(decoder_input_val)\n",
    "decoder_target_val = tar_tokenizer.texts_to_sequences(decoder_target_val)\n",
    "\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425fb3c4",
   "metadata": {},
   "source": [
    "**^^^^ 위 AttributeError는 정수 변환이후 재실행하며 일어난 오류 ^^^^**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86834571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 870, 80, 417, 3, 744, 15, 483, 407, 7, 361], [1, 22, 35, 44, 1015, 1503, 3, 18, 1167], [1, 139, 955, 3, 871, 7, 1781], [1, 4, 671, 4, 198, 250], [1, 94, 1052, 1678, 9, 1066, 402, 157, 79, 29]]\n",
      "target\n",
      "decoder  [[870, 80, 417, 3, 744, 15, 483, 407, 7, 361, 2], [22, 35, 44, 1015, 1503, 3, 18, 1167, 2], [139, 955, 3, 871, 7, 1781, 2], [4, 671, 4, 198, 250, 2], [94, 1052, 1678, 9, 1066, 402, 157, 79, 29, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a5612",
   "metadata": {},
   "source": [
    "**2.8.3 요약문 길이 1인 경우, 삭제**  \n",
    "이제 길이가 0이 된 요약문의 실제 길이는 1로 나올 거예요. 길이 0이 된 decoder_input에는 sostoken, decoder_target에는 eostoken만 남아 있을 테니까요.\n",
    "\n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장해볼게요. 이 샘플들은 모두 삭제할 거예요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8644b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 7\n",
      "삭제할 테스트 데이터의 개수 : 2\n",
      "삭제할 테스트 데이터의 개수 : 4\n",
      "훈련 데이터의 개수 : 49173\n",
      "훈련 레이블의 개수 : 49173\n",
      "검증 데이터의 개수 : 29506\n",
      "검증 레이블의 개수 : 29506\n",
      "테스트 데이터의 개수 : 19668\n",
      "테스트 레이블의 개수 : 19668\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_val = [index for index, sentence in enumerate(decoder_input_val) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_val))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_val = [sentence for index, sentence in enumerate(encoder_input_val) if index not in drop_val]\n",
    "decoder_input_val = [sentence for index, sentence in enumerate(decoder_input_val) if index not in drop_val]\n",
    "decoder_target_val = [sentence for index, sentence in enumerate(decoder_target_val) if index not in drop_val]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('검증 데이터의 개수 :', len(encoder_input_val))\n",
    "print('검증 레이블의 개수 :', len(decoder_input_val))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ea603",
   "metadata": {},
   "source": [
    "**2.8.4 패딩하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc6c0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_val = pad_sequences(encoder_input_val, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "\n",
    "decoder_input_train  = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "\n",
    "decoder_input_val  = pad_sequences(decoder_input_val, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_val = pad_sequences(decoder_target_val, maxlen=summary_max_len, padding='post')\n",
    "\n",
    "decoder_input_test  = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8c798",
   "metadata": {},
   "source": [
    "## **Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af722cd4",
   "metadata": {},
   "source": [
    "  - 3.1 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fdde252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "695f4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "# encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "x = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "# encoder_output2, state_h2, state_c2 = encoder_lstm2(enc_emb)\n",
    "x = encoder_lstm2(x)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "# encoder_output3, state_h3, state_c3 = encoder_lstm3(enc_emb)\n",
    "encoder_output, state_h, state_c = encoder_lstm3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96f6088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4c6d836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 50, 128)      1024000     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, 50, 256), (N 394240      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 50, 256), (N 525312      lstm_7[0][0]                     \n",
      "                                                                 lstm_7[0][1]                     \n",
      "                                                                 lstm_7[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 128)    256000      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 50, 256), (N 525312      lstm_8[0][0]                     \n",
      "                                                                 lstm_8[0][1]                     \n",
      "                                                                 lstm_8[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, None, 256),  394240      embedding_4[0][0]                \n",
      "                                                                 lstm_9[0][1]                     \n",
      "                                                                 lstm_9[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   514000      lstm_10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6a855c52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"embedding\". The following previous layers were accessed without issue: ['embedding_3', 'lstm_7', 'lstm_8']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3951395592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 모델 정의\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_softmax_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    193\u001b[0m         self.inputs, self.outputs)\n\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             raise ValueError('Graph disconnected: '\n\u001b[0m\u001b[1;32m    980\u001b[0m                              \u001b[0;34m'cannot obtain value for tensor '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                              \u001b[0;34m' at layer \"'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\". '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"embedding\". The following previous layers were accessed without issue: ['embedding_3', 'lstm_7', 'lstm_8']"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_output1])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180b8c6",
   "metadata": {},
   "source": [
    "  - 3.2 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eadfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_val, decoder_input_val], decoder_target_val), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab7074",
   "metadata": {},
   "source": [
    "  - 3.3 학습 결과 시각화 (train loss vs. val loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38703e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4adc5b",
   "metadata": {},
   "source": [
    "  - 3.4 인퍼런스모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89122387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_output, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5f2f762",
   "metadata": {},
   "source": [
    "**Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55336b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if ((i != 0) and (i != tar_word_to_index['sostoken']) and (i != tar_word_to_index['eostoken'])):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefa46c",
   "metadata": {},
   "source": [
    "**Step 5. Summa을 이용해서 추출적 요약해보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66bc41",
   "metadata": {},
   "source": [
    "  - Summa의 summarize를 사용하여 추출적 요약 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf063dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text\n",
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fbdbe",
   "metadata": {},
   "source": [
    "  - 표로 비교하기(추상적 vs. 추출적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, words=100, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a94631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d39d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
