{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7b33228d",
      "metadata": {
        "id": "7b33228d"
      },
      "source": [
        "### 코더의 소회 :\n",
        "날씨 : 오늘의 학습 < 보통☁️>했습니다. [☀️⛅☁️🌧️🌩️⛈️]\n",
        "- 배운점 : 진행하고자하는 훈련에 꼭! 기 원하는 옵션이 있다면 모델 설계때 모델 구성요소(ex.옵티마이저저 등)에 **해당 기능을 지원하는가**, 지원하지 않으면 다른 비슷한 대안이 있는가 알아보면 좋을 것 같다.\n",
        "- 아쉬운점 : Matrix까지 실행하지 못하였던게 아쉽습니다. 엉뚱한 곳(파일 압축해제 함수화)에서 오전 시간을 다 사용한 것이 아쉽습니다. 영번역까지 해보고싶습니다.  \n",
        "- 느낀점 :  \n",
        "\n",
        "(참고 : https://github.com/Annyong2/AIFFEL_quest_rs/tree/master/GoingDeeper/Gdr05)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37ccd71b",
      "metadata": {
        "id": "37ccd71b"
      },
      "source": [
        "### 전체 코드 실행 플로우 (목차):\n",
        "\n",
        "**STEP 1. 불러오기 : 라이브러리 & 데이터**  \n",
        "\n",
        "**STEP 2. 데이터 정제 및 토큰화**  \n",
        "\n",
        "**STEP 3. 모델 설계**  \n",
        "\n",
        "**STEP 4. 모델 훈련**  \n",
        "\n",
        "**STEP 5. 번역 및 시각화**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b46bb90f",
      "metadata": {
        "id": "b46bb90f"
      },
      "source": [
        "**[TIP] STEP 4. 모델 설계**\n",
        "- 한국어를 영어로 잘 번역해 줄 멋진 Attention 기반 Seq2seq 모델을 설계하세요!\n",
        "- 앞서 만든 모델에 Dropout 모듈을 추가하면 성능이 더 좋아집니다!\n",
        "- Embedding Size와 Hidden Size는 실험을 통해 적당한 값을 맞춰 주도록 합니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8d9fdc",
      "metadata": {
        "id": "8b8d9fdc"
      },
      "source": [
        "**[TIP] STEP 5. 모델 훈련**  \n",
        "- traing loss 안정적으로 떨어지면서 학습 진행  \n",
        "  \n",
        "**[TIP] STEP 6. 모델 평가(테스트)**  \n",
        "- 데스트용 디코더 모델의 출력 결과가 정답과 어느 정도 유사한 영번역 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31ae222",
      "metadata": {
        "id": "b31ae222"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55e1234d",
      "metadata": {
        "id": "55e1234d"
      },
      "source": [
        "# STEP 1. 불러오기 : 라이브러리 & 데이터   \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5e35d20",
      "metadata": {
        "id": "c5e35d20"
      },
      "source": [
        "### 1.1 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "aa696ce3",
      "metadata": {
        "id": "aa696ce3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "import os\n",
        "import sentencepiece as spm\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm  # 폰트 설정\n",
        "\n",
        "\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "\n",
        "import seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d3cb0079",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cb0079",
        "outputId": "d6595baa-f69a-4790-d9ce-5feb13f84105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "완료!\n"
          ]
        }
      ],
      "source": [
        "# 한글설정\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "mpl.font_manager.findfont(font)\n",
        "\n",
        "print(\"완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7agOfILkfaL",
        "outputId": "923d5514-2198-490c-b80e-0090342ced41"
      },
      "id": "Q7agOfILkfaL",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3baf27b3",
      "metadata": {
        "id": "3baf27b3"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 저장경로\n",
        "# data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
        "kor_path = '/content/drive/MyDrive/camp/korean-english-park.train.ko' # data_dir+\"/korean-english-park.train.ko\"\n",
        "eng_path = '/content/drive/MyDrive/camp/korean-english-park.train.en' # data_dir+\"/korean-english-park.train.en\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b739a233",
      "metadata": {
        "id": "b739a233"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a34b7c",
      "metadata": {
        "id": "c9a34b7c"
      },
      "source": [
        "데이터 출처 : https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f5a10d",
      "metadata": {
        "id": "05f5a10d"
      },
      "source": [
        "#### 1.3 데이터 확인 : TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "7dac6ea9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dac6ea9",
        "outputId": "9cd51047-3836-4461-e32a-32899f027860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
            ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
            ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
            ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
            ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
          ]
        }
      ],
      "source": [
        "# KOREAN\n",
        "# 데이터 형태 확인\n",
        "with open(kor_path, \"r\") as f:\n",
        "    raw_ko = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_ko))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen_ko in raw_ko[0:100][::20]: print(\">>\", sen_ko)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "09ba9ac4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ba9ac4",
        "outputId": "5ab92c84-1d21-48d1-cf4d-bfe5d0dfad0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> Much of personal computing is about \"can you top this?\"\n",
            ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
            ">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",
            ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
            ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
          ]
        }
      ],
      "source": [
        "# ENGLISH\n",
        "# 데이터 형태 확인\n",
        "with open(eng_path, \"r\") as f:\n",
        "    raw_en = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_en))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen_en in raw_en[0:100][::20]: print(\">>\", sen_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "499d98d8",
      "metadata": {
        "id": "499d98d8"
      },
      "source": [
        "##### 코멘트:\n",
        "한국어데이터와 영어데이터 크기가 동일하다.    \n",
        "두 파일로 나눠져있는 데이터들은 순서(idx)도 매핑되어있다.(raw_ko[1] = raw_en[1])      \n",
        "=> 병렬로 묶는다"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d042d192",
      "metadata": {
        "id": "d042d192"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7204b527",
      "metadata": {
        "id": "7204b527"
      },
      "source": [
        "# Step 2. 데이터 정제 및 토큰화   \n",
        "\n",
        "2.1 데이터 정제  \n",
        "2.2 데이터 토큰화  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd08979c",
      "metadata": {
        "id": "bd08979c"
      },
      "source": [
        "### 2.1.1 데이터 정제 : 병렬 데이터셋 생성 및 중복제거(set()사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "4749410f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4749410f",
        "outputId": "3ea1bc9b-cfc3-4082-dcdb-7af325a7f3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "병렬 데이터셋 생성 완료\n",
            "병렬 데이터셋 중복제거 완료 : 94123 ->78968 \n",
            "\n",
            "Type(cleaned_corpus) :  <class 'list'> \n",
            " [('갤럽 여론조사는 1930년대부터 실시됐지만 대통령에 대한 지지율을 월별로 발표한 것은 트루먼 시대부터다.', \"While Gallup polling goes back to the 1930s, it wasn't until the Truman years that they began surveying monthly approval ratings.\")]\n"
          ]
        }
      ],
      "source": [
        "def clean_corpus(kor_path, eng_path):\n",
        "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
        "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
        "    assert len(kor) == len(eng)\n",
        "\n",
        "    dataset = list(zip(kor, eng))\n",
        "    print(\"병렬 데이터셋 생성 완료\")\n",
        "    cleaned_corpus = list(set(dataset))\n",
        "    print(f\"병렬 데이터셋 중복제거 완료 : {len(dataset)} ->{len(cleaned_corpus)}\",\"\\n\")\n",
        "    ko_corpus, en_corpus = zip(*cleaned_corpus)\n",
        "\n",
        "    return cleaned_corpus, ko_corpus, en_corpus\n",
        "\n",
        "\n",
        "cleaned_corpus, ko_corpus, en_corpus = clean_corpus(kor_path, eng_path)\n",
        "\n",
        "print(\"Type(cleaned_corpus) : \", type(cleaned_corpus),\"\\n\",cleaned_corpus[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dcffccd",
      "metadata": {
        "id": "6dcffccd"
      },
      "source": [
        "##### 중복제거 후 코멘트 :\n",
        "\n",
        "\n",
        "영한 데이터를 병렬구조로 만들고, set()매써드 사용하여 중복제거를 하였다.  \n",
        "\n",
        "데이터 중복 제거후, 데이터는 이전의 80%(94123 ->78968)정도 남았다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd54780d",
      "metadata": {
        "id": "dd54780d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73570d0",
      "metadata": {
        "id": "e73570d0"
      },
      "source": [
        "### 2.1.2 데이터 정제 : 데이터 전처리 (lms 4가지 반영 완료)\n",
        "- 모든 입력을 소문자로 변환\n",
        "- 알파벳, 문장부호, 한글만 남기고 모두 제거\n",
        "- 문장부호 양옆에 공백을 추가\n",
        "- 문장 앞뒤의 불필요한 공백을 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e561e4f",
      "metadata": {
        "id": "2e561e4f"
      },
      "source": [
        "##### 전처리 함수 preprocess_sentence 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "7b3a11bd",
      "metadata": {
        "id": "7b3a11bd"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    # 1. 소문자 변환\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # 2. 알파벳, 문장부호, 한글 외 제거\n",
        "    sentence = re.sub(r'\\d', '', sentence)\n",
        "\n",
        "    # 3. 문장부호 양옆 공백 추가\n",
        "    sentence = re.sub(r'(\\W)', r' \\1 ', sentence)\n",
        "\n",
        "    # 4. 문장 앞뒤 공백 제거\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    # 5. 중복된 공백 제거\n",
        "    # sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7d0ebef",
      "metadata": {
        "id": "b7d0ebef"
      },
      "source": [
        "##### 전처리 함수 preprocess_sentence작동 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "6f80e0dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f80e0dc",
        "outputId": "398bf184-4b97-4146-fa99-a3c6b9b080cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "미하일 카미닌 러시아 외무부 대변인은 기자회견에서 “러시아가 19일 4명의 영국 외교관을 추방한 것은 영국 정부가 취한 조치에 대한 반응이다”라고 발표했다.\n",
            "미하일   카미닌   러시아   외무부   대변인은   기자회견에서    “ 러시아가   일   명의   영국   외교관을   추방한   것은   영국   정부가   취한   조치에   대한   반응이다 ” 라고   발표했다 .\n"
          ]
        }
      ],
      "source": [
        "# 확인\n",
        "text = '미하일 카미닌 러시아 외무부 대변인은 기자회견에서 “러시아가 19일 4명의 영국 외교관을 추방한 것은 영국 정부가 취한 조치에 대한 반응이다”라고 발표했다.'\n",
        "print(text)\n",
        "print(preprocess_sentence(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd9edba",
      "metadata": {
        "id": "4dd9edba"
      },
      "source": [
        "### 2.2.1 데이터 토큰화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df18ea04",
      "metadata": {
        "id": "df18ea04"
      },
      "source": [
        "##### 토큰화 함수 generate_tokenizer 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a2008ec5",
      "metadata": {
        "id": "a2008ec5"
      },
      "outputs": [],
      "source": [
        "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
        "# 코퍼스를 파일로 저장하고 SentencePiece에서 처리하도록 수정\n",
        "def save_corpus(corpus, filepath):\n",
        "    with open(filepath, 'w') as f:\n",
        "        for line in corpus:\n",
        "            f.write(f\"{line}\\n\")\n",
        "\n",
        "# SentencePiece에서 파일을 입력으로 사용\n",
        "def generate_tokenizer(corpus,\n",
        "                       vocab_size,\n",
        "                       lang=\"ko\",\n",
        "                       pad_id=0,\n",
        "                       bos_id=1,\n",
        "                       eos_id=2,\n",
        "                       unk_id=3):\n",
        "    corpus_file = f\"{lang}_corpus.txt\"\n",
        "    save_corpus(corpus, corpus_file)\n",
        "\n",
        "    # SentencePiece 학습 시 병렬 처리 옵션 추가\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=corpus_file,\n",
        "        model_prefix=f\"{lang}_tokenizer\",\n",
        "        vocab_size=vocab_size,\n",
        "        pad_id=pad_id,\n",
        "        bos_id=bos_id,\n",
        "        eos_id=eos_id,\n",
        "        unk_id=unk_id,\n",
        "        num_threads=4  # 병렬 처리 옵션 추가\n",
        "    )\n",
        "\n",
        "    # 학습된 모델 불러오기\n",
        "    tokenizer = spm.SentencePieceProcessor()\n",
        "    tokenizer.Load(f\"{lang}_tokenizer.model\")\n",
        "\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b78430",
      "metadata": {
        "id": "24b78430"
      },
      "source": [
        "##### 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "21acc024",
      "metadata": {
        "id": "21acc024"
      },
      "outputs": [],
      "source": [
        "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
        "\n",
        "N = len(cleaned_corpus)\n",
        "kor_corpus = []\n",
        "eng_corpus = []\n",
        "for i in range(N):\n",
        "    kor_corpus.append(preprocess_sentence(ko_corpus[i]))\n",
        "    eng_corpus.append(preprocess_sentence(en_corpus[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ca68bf79",
      "metadata": {
        "id": "ca68bf79"
      },
      "outputs": [],
      "source": [
        "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "85fc8a6f",
      "metadata": {
        "id": "85fc8a6f"
      },
      "outputs": [],
      "source": [
        "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "952cfb8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "952cfb8f",
        "outputId": "fdfee161-5926-4324-f7eb-1d61d70ed628"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "79094d7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "912b023c63d14a44a74225ca50d5189f",
            "b9d71bbbd03342cdb536efa482d98bcb",
            "5356b1fff7344b5691d8340249a93748",
            "4670bef805c6415aa608ccc7b4e1fd44",
            "824ee3fd77d545c6a26bd1bd4eab58d8",
            "b3a24bdb32fa42c7876bd1acf998e212",
            "4677e172b82d430a84f11efce50f2285",
            "f1b98ee40f8d41f29a354758e32bad6d",
            "c23d51bf17c641aba9d03d7b66374186",
            "97270071a3c6451aa511c927b319a6bd",
            "399c9d7fc11045d3b7dfae948de01122"
          ]
        },
        "id": "79094d7c",
        "outputId": "7c63f10b-25a3-4d57-8189-b0d352ec512e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/78968 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "912b023c63d14a44a74225ca50d5189f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2151\n",
            "2151\n"
          ]
        }
      ],
      "source": [
        "src_corpus = []\n",
        "tgt_corpus = []\n",
        "\n",
        "assert len(kor_corpus) == len(eng_corpus)\n",
        "\n",
        "# 토큰의 길이가 50 이하인 문장만 남깁니다.\n",
        "for idx in tqdm(range(len(kor_corpus))):\n",
        "    if len(kor_corpus[idx]) <= 50 and len(eng_corpus[idx]) <= 50:  # len(kor_corpus[idx]) <= 50:\n",
        "        src_corpus.append(kor_corpus[idx])\n",
        "        tgt_corpus.append(eng_corpus[idx])\n",
        "    else :\n",
        "        pass\n",
        "\n",
        "print(len(src_corpus))\n",
        "print(len(tgt_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d6af689b",
      "metadata": {
        "id": "d6af689b"
      },
      "outputs": [],
      "source": [
        "# ko_tokenizer와 en_tokenizer를 사용하여 텍스트를 정수 시퀀스로 변환\n",
        "src_corpus_tokenized = [ko_tokenizer.encode_as_ids(sentence) for sentence in src_corpus]\n",
        "tgt_corpus_tokenized = [en_tokenizer.encode_as_ids(sentence) for sentence in tgt_corpus]\n",
        "\n",
        "# 패딩처리를 완료하여 학습용 데이터를 완성합니다.\n",
        "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus_tokenized, padding='post')\n",
        "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus_tokenized, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e73d16e",
      "metadata": {
        "id": "7e73d16e"
      },
      "source": [
        "👁️👁️**코멘트 :**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ad4125",
      "metadata": {
        "id": "40ad4125"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e5f7ec1",
      "metadata": {
        "id": "7e5f7ec1"
      },
      "source": [
        "# STEP 3. 모델 설계  \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "f46fd2f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46fd2f8",
        "outputId": "fb6c63bc-154e-4872-9b2f-4b69a3c66a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class PoswiseFeedForwardNet, return out\n",
            "class MultiHeadAttention, return out, attention_weights\n",
            "class EncoderLayer, return out, enc_attn\n",
            "슝=3\n",
            "class Encoder, return out, enc_attns\n",
            "class Decoder, return out, dec_attns, dec_enc_attns\n"
          ]
        }
      ],
      "source": [
        "## PositionalEncoding\n",
        "## 용도 : 입력 위치에 따라 위치 인코딩 값을 계산하여 반환합니다.\n",
        "def PositionalEncoding(pos, d_model):\n",
        "    def cal_angle(position, i):\n",
        "        return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "    return sinusoid_table\n",
        "\n",
        "print(\"class PoswiseFeedForwardNet, return out\")\n",
        "\n",
        "\n",
        "## MultiHeadAttention\n",
        "## 용도 : 입력에 대한 여러 헤드의 어텐션을 계산하여 결합합니다.\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        # Linear Layers for Q, K, V\n",
        "        self.W_q = tf.keras.layers.Dense(d_model)\n",
        "        self.W_k = tf.keras.layers.Dense(d_model)\n",
        "        self.W_v = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        # Output linear layer\n",
        "        self.linear = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "\n",
        "        # Scaled QK^T / sqrt(d_k)\n",
        "        scaled_qk = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(d_k)\n",
        "\n",
        "        # Add the mask to the scaled tensor\n",
        "        if mask is not None:\n",
        "            scaled_qk += (mask * -1e9)\n",
        "\n",
        "        # Softmax over the last axis to get attention weights\n",
        "        attention_weights = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "\n",
        "        # Multiply the attention weights by the values\n",
        "        out = tf.matmul(attention_weights, V)\n",
        "\n",
        "        return out, attention_weights\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Split the embedding into num_heads for parallel processing\n",
        "        batch_size = x.shape(x)[0]\n",
        "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        split_x = tf.transpose(x, perm=[0, 2, 1, 3])  # [batch, heads, length, depth]\n",
        "        return split_x\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine the split heads back into the original shape\n",
        "        batch_size = x.shape(x)[0]\n",
        "        combine_heads_x = tf.transpose(x, perm=[0, 2, 1, 3])  # [batch, length, heads, depth]\n",
        "        combine_heads_x = tf.reshape(x, (batch_size, -1, self.d_model))\n",
        "        return combine_heads_x\n",
        "\n",
        "    def call(self, Q, K, V, mask):\n",
        "        # Step 1: Linear transformation for Q, K, V\n",
        "        WQ = self.W_q(Q)\n",
        "        WK = self.W_k(K)\n",
        "        WV = self.W_v(V)\n",
        "\n",
        "        # Step 2: Split heads\n",
        "        WQ_split = self.split_heads(WQ)\n",
        "        WK_split = self.split_heads(WK)\n",
        "        WV_split = self.split_heads(WV)\n",
        "\n",
        "        # Step 3: Scaled Dot-Product Attention\n",
        "        out, attention_weights = self.scaled_dot_product_attention(\n",
        "            WQ_split, WK_split, WV_split, mask)\n",
        "\n",
        "        # Step 4: Combine heads\n",
        "        out = self.combine_heads(out)\n",
        "\n",
        "        # Step 5: Final linear layer\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out, attention_weights\n",
        "\n",
        "\n",
        "## PoswiseFeedForwardNet\n",
        "## 용도 : 각 위치별로 완전 연결 신경망을 적용하여 비선형 변환을 수행합니다.\n",
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.w_1(x)\n",
        "        out = self.w_2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"class MultiHeadAttention, return out, attention_weights\")\n",
        "\n",
        "## EncoderLayer\n",
        "## 용도 : 입력을 인코더에 전달하여 어텐션 및 피드포워드 네트워크를 적용합니다.\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, enc_attn\n",
        "\n",
        "print(\"class EncoderLayer, return out, enc_attn\")\n",
        "\n",
        "## DecoderLayer\n",
        "## 용도 : 입력을 디코더에 전달하여 어텐션 및 피드포워드 네트워크를 적용합니다.\n",
        "# DecoderLayer 클래스를 작성하세요.\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.dec_mask_attn = MultiHeadAttention(d_model, n_heads)  # Masked Attention\n",
        "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)  # Encoder-Decoder Attention\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        # Layer Normalization 추가\n",
        "        self.norm_0 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        \"\"\"\n",
        "        Masked Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x  # Residual connection 설정\n",
        "        out = self.norm_0(x)  # 입력 정규화\n",
        "        out, mask_attn = self.dec_mask_attn(out, out, out, causality_mask)  # causality_mask 사용\n",
        "        out = self.dropout(out)\n",
        "        out += residual  # Residual connection 적용\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention (Encoder-Decoder Attention)\n",
        "        \"\"\"\n",
        "        residual = out  # 여기서 x가 아니라 out을 residual로 사용해야 합니다.\n",
        "        out = self.norm_1(out)  # 앞에서 나온 out을 정규화\n",
        "        out, dec_attn = self.dec_self_attn(out, enc_out, enc_out, padding_mask)  # padding_mask 사용\n",
        "        out = self.dropout(out)\n",
        "        out += residual  # Residual connection 적용\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out  # Feed Forward 전에도 residual을 설정해야 함\n",
        "        out = self.norm_2(out)  # 정규화\n",
        "        out = self.ffn(out)  # Feed Forward Network 적용\n",
        "        out = self.dropout(out)\n",
        "        out += residual  # Residual connection 적용\n",
        "\n",
        "        return out, mask_attn, dec_attn  # Masked Self-Attention과 Encoder-Decoder Attention의 결과 반환\n",
        "\n",
        "print(\"슝=3\")\n",
        "\n",
        "\n",
        "## Encoder\n",
        "## 용도 : 여러 개의 인코더 레이어를 쌓아 전체 인코더를 구성합니다.\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                        for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        out = x\n",
        "\n",
        "        enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, enc_attn = self.enc_layers[i](out, mask)\n",
        "            enc_attns.append(enc_attn)\n",
        "\n",
        "        return out, enc_attns\n",
        "\n",
        "print(\"class Encoder, return out, enc_attns\")\n",
        "\n",
        "## Decoder\n",
        "## 용도 : 여러 개의 디코더 레이어를 쌓아 전체 디코더를 구성합니다.\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                            for _ in range(n_layers)]\n",
        "\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        out = x\n",
        "\n",
        "        dec_attns = list()\n",
        "        dec_enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, dec_attn, dec_enc_attn = \\\n",
        "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "            dec_attns.append(dec_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "        return out, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"class Decoder, return out, dec_attns, dec_enc_attns\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer\n",
        "## 용도 : 인코더와 디코더를 결합하여 전체 트랜스포머 모델을 구성합니다.\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 src_vocab_size,\n",
        "                 tgt_vocab_size,\n",
        "                 pos_len,\n",
        "                 dropout=0.2,\n",
        "                 shared=False):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.shared = shared\n",
        "\n",
        "        # 1. Embedding Layer 정의\n",
        "        self.src_embedding = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # 2. Positional Encoding 정의\n",
        "        self.pos_encoding = PositionalEncoding(pos_len, d_model)\n",
        "        # 6. Dropout 정의\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        # 3. Encoder / Decoder 정의\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        # 4. Output Linear 정의\n",
        "        self.out_linear = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "        self.shared = shared\n",
        "\n",
        "        # 5. Shared Weights\n",
        "        if shared: self.out_linear.set_weights(tf.transpose(self.tgt_embedding.weights))\n",
        "\n",
        "\n",
        "    def embedding(self, emb, x):\n",
        "        seq_len = x.shape[1]\n",
        "        out = emb(x)\n",
        "\n",
        "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "        out = self.dropout(out)\n",
        "\n",
        "\n",
        "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "        \"\"\"\n",
        "        순서에 따라 Encoder, Decoder, 그리고 Output 계산\n",
        "        \"\"\"\n",
        "        enc_in = self.embedding(self.src_embedding, enc_in)\n",
        "        dec_in = self.embedding(self.tgt_embedding, dec_in)\n",
        "\n",
        "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "\n",
        "        dec_out, dec_attns, dec_enc_attns = \\\n",
        "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "\n",
        "        # Step 4: Out Linear(dec_out)\n",
        "        logits = self.out_linear(dec_out)\n",
        "\n",
        "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"Transformer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqYMyJNEyWyZ",
        "outputId": "2aca9057-ecb7-4763-b6d8-35c2da3e0560"
      },
      "id": "GqYMyJNEyWyZ",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64884fe0",
      "metadata": {
        "id": "64884fe0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803d6c43",
      "metadata": {
        "id": "803d6c43"
      },
      "source": [
        "# STEP 4. 모델 훈련\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "c7b5e084",
      "metadata": {
        "id": "c7b5e084"
      },
      "outputs": [],
      "source": [
        "def generate_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "'''\n",
        "def generate_causality_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "'''\n",
        "# generate_causality_mask 함수 수정\n",
        "def generate_causality_mask(tgt):\n",
        "    size = tf.shape(tgt)[1]  # 시퀀스 길이 추출\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def generate_masks(src, tgt):\n",
        "    enc_mask = generate_padding_mask(src)\n",
        "    dec_mask = generate_causality_mask(tgt)\n",
        "    dec_enc_mask = generate_padding_mask(tgt)\n",
        "\n",
        "    return enc_mask, dec_enc_mask, dec_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "300ce39c",
      "metadata": {
        "id": "300ce39c"
      },
      "outputs": [],
      "source": [
        "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(LearningRateScheduler, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = step ** -0.5\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "4ba81c9d",
      "metadata": {
        "scrolled": true,
        "id": "4ba81c9d"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(n_layers=2,\n",
        "                          d_model=512,\n",
        "                          n_heads=8,\n",
        "                          d_ff=2048,\n",
        "                          src_vocab_size=SRC_VOCAB_SIZE,\n",
        "                          tgt_vocab_size=TGT_VOCAB_SIZE,\n",
        "                          pos_len=50,\n",
        "                          shared=True\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "2116b111",
      "metadata": {
        "id": "2116b111"
      },
      "outputs": [],
      "source": [
        "learning_rate = LearningRateScheduler(512.0)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "e603b998",
      "metadata": {
        "id": "e603b998"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "cc5e934f",
      "metadata": {
        "id": "cc5e934f"
      },
      "outputs": [],
      "source": [
        "@tf.function()\n",
        "def train_step(src, tgt, model, optimizer):\n",
        "    gold = tgt[:, 1:]\n",
        "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # predictions 계산을 tape 컨텍스트 내에서 수행하여 그래디언트 계산을 보장합니다.\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
        "        loss = loss_function(gold, predictions[:, :-1])\n",
        "\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # tf.function에서 값들을 제대로 캡처하도록 딕셔너리 형태로 반환합니다.\n",
        "    return {'loss': loss, 'enc_attns': enc_attns, 'dec_attns': dec_attns, 'dec_enc_attns': dec_enc_attns}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2f749c",
      "metadata": {
        "id": "de2f749c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7affabb",
      "metadata": {
        "id": "e7affabb"
      },
      "source": [
        "# STEP 5. 번역 및 시각화  \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "ab4d7fb4",
      "metadata": {
        "id": "ab4d7fb4"
      },
      "outputs": [],
      "source": [
        "# 번역 생성 함수\n",
        "\n",
        "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
        "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
        "\n",
        "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    ids = []\n",
        "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
        "    for i in range(dec_train.shape[-1]):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
        "        generate_masks(_input, output)\n",
        "\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
        "        model(_input,\n",
        "              output,\n",
        "              enc_padding_mask,\n",
        "              combined_mask,\n",
        "              dec_padding_mask)\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
        "\n",
        "        if tgt_tokenizer.eos_id() == predicted_id:\n",
        "            result = tgt_tokenizer.decode_ids(ids)\n",
        "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "        ids.append(predicted_id)\n",
        "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
        "\n",
        "    result = tgt_tokenizer.decode_ids(ids)\n",
        "\n",
        "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "bf99240a",
      "metadata": {
        "id": "bf99240a"
      },
      "outputs": [],
      "source": [
        "# Attention 시각화 함수\n",
        "\n",
        "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
        "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
        "        import seaborn\n",
        "        seaborn.heatmap(data,\n",
        "                        square=True,\n",
        "                        vmin=0.0, vmax=1.0,\n",
        "                        cbar=False, ax=ax,\n",
        "                        xticklabels=x,\n",
        "                        yticklabels=y)\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Encoder Layer\", layer + 1)\n",
        "        for h in range(4):\n",
        "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
        "        plt.show()\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Decoder Self Layer\", layer+1)\n",
        "        for h in range(4):\n",
        "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Decoder Src Layer\", layer+1)\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        for h in range(4):\n",
        "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "8c69d3c2",
      "metadata": {
        "id": "8c69d3c2"
      },
      "outputs": [],
      "source": [
        "# 번역 생성 및 Attention 시각화 결합\n",
        "\n",
        "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
        "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    if plot_attention:\n",
        "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "6d3dc349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791,
          "referenced_widgets": [
            "a64fefb56784415d8d239c08f08cff24",
            "92efff39bde945ab9afe34fdbbfbd3a4",
            "bfa97c3017e849d1b84180bc9902aaab",
            "bb2a394a599a4d36be18ca1fe6312a4f",
            "60788aaa6c814addbd209cd07f54be03",
            "f1ca046e033b48b898944d6e76a693a1",
            "45bdcb3cccb743aa914c6c83c652c0b3",
            "1cee12b7765446a18df588b206b15892",
            "3a98270559894096a3f18986345167d4",
            "d07f95396f3b498d9773dfeb81819493",
            "e1584818d67844058017788e1f70605e"
          ]
        },
        "id": "6d3dc349",
        "outputId": "3ada9879-f4f9-4653-edea-3c0728d477c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/34 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a64fefb56784415d8d239c08f08cff24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"<ipython-input-76-d70836a03263>\", line 8, in train_step  *\n        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"<ipython-input-144-43d15ff6954a>\", line 56, in call\n        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 217, in call\n        out, enc_attn = self.enc_layers[i](out, mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 128, in call\n        out = self.norm_1(x)\n\n    TypeError: Exception encountered when calling EncoderLayer.call().\n    \n    \u001b[1m'NoneType' object is not subscriptable\u001b[0m\n    \n    Arguments received by EncoderLayer.call():\n      • x=None\n      • mask=tf.Tensor(shape=(64, 1, 1, 22), dtype=float32)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-a9f91f57a657>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 학습 단계 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# train_step에서 반환된 딕셔너리를 unpacking하도록 코드를 변경했습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         result = train_step(src=enc_train[idx:idx+BATCH_SIZE],\n\u001b[0m\u001b[1;32m     22\u001b[0m                             \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file0qa92shs.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(src, tgt, model, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-144-43d15ff6954a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-2c1ad4714ddc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0menc_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-2c1ad4714ddc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[1;32m    127\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_self_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-76-d70836a03263>\", line 8, in train_step  *\n        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"<ipython-input-144-43d15ff6954a>\", line 56, in call\n        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 217, in call\n        out, enc_attn = self.enc_layers[i](out, mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 128, in call\n        out = self.norm_1(x)\n\n    TypeError: Exception encountered when calling EncoderLayer.call().\n    \n    \u001b[1m'NoneType' object is not subscriptable\u001b[0m\n    \n    Arguments received by EncoderLayer.call():\n      • x=None\n      • mask=tf.Tensor(shape=(64, 1, 1, 22), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5  # 학습할 Epoch 수\n",
        "BATCH_SIZE = 64  # 배치 크기\n",
        "\n",
        "example_sentences = [\n",
        "    \"오바마는 대통령이다.\"\n",
        "    \"시민들은 도시 속에 산다.\"\n",
        "    \"커피는 필요 없다.\"\n",
        "    \"일곱 명의 사망자가 발생했다.\"\n",
        "]\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0.0  # total_loss를 부동 소수점으로 초기화\n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)    # tqdm 진행 바 사용\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        # 학습 단계 실행\n",
        "        # train_step에서 반환된 딕셔너리를 unpacking하도록 코드를 변경했습니다.\n",
        "        result = train_step(src=enc_train[idx:idx+BATCH_SIZE],\n",
        "                            tgt=dec_train[idx:idx+BATCH_SIZE],\n",
        "                            model=transformer,\n",
        "                            optimizer=optimizer)\n",
        "        if result is not None:\n",
        "            batch_loss, enc_attns, dec_attns, dec_enc_attns = result['loss'], result['enc_attns'], result['dec_attns'], result['dec_enc_attns']\n",
        "            total_loss += batch_loss.numpy() if hasattr(batch_loss, 'numpy') else batch_loss # batch_loss가 Tensor일 경우 NumPy 스칼라로 변환\n",
        "        else:\n",
        "            print(f\"Warning: train_step returned None for batch {batch}, idx {idx}\")\n",
        "            # 이 경우 처리 방안을 고려하세요. 예: 배치 건너뛰기 또는 예외 발생\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss / (batch + 1))) # total_loss가 이제 부동 소수점이므로 .numpy() 제거\n",
        "\n",
        "    for example_sentence in tqdm(example_sentences): # example_sentences를 example_sentence로 변경하여 리스트의 각 문장을 반복\n",
        "        translate(example_sentence, transformer, ko_tokenizer, en_tokenizer, plot_attention=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0ffd0a",
      "metadata": {
        "id": "fc0ffd0a"
      },
      "source": [
        "**결론:**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "912b023c63d14a44a74225ca50d5189f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9d71bbbd03342cdb536efa482d98bcb",
              "IPY_MODEL_5356b1fff7344b5691d8340249a93748",
              "IPY_MODEL_4670bef805c6415aa608ccc7b4e1fd44"
            ],
            "layout": "IPY_MODEL_824ee3fd77d545c6a26bd1bd4eab58d8"
          }
        },
        "b9d71bbbd03342cdb536efa482d98bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a24bdb32fa42c7876bd1acf998e212",
            "placeholder": "​",
            "style": "IPY_MODEL_4677e172b82d430a84f11efce50f2285",
            "value": "100%"
          }
        },
        "5356b1fff7344b5691d8340249a93748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b98ee40f8d41f29a354758e32bad6d",
            "max": 78968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c23d51bf17c641aba9d03d7b66374186",
            "value": 78968
          }
        },
        "4670bef805c6415aa608ccc7b4e1fd44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97270071a3c6451aa511c927b319a6bd",
            "placeholder": "​",
            "style": "IPY_MODEL_399c9d7fc11045d3b7dfae948de01122",
            "value": " 78968/78968 [00:00&lt;00:00, 494216.11it/s]"
          }
        },
        "824ee3fd77d545c6a26bd1bd4eab58d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a24bdb32fa42c7876bd1acf998e212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4677e172b82d430a84f11efce50f2285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1b98ee40f8d41f29a354758e32bad6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23d51bf17c641aba9d03d7b66374186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97270071a3c6451aa511c927b319a6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399c9d7fc11045d3b7dfae948de01122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a64fefb56784415d8d239c08f08cff24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92efff39bde945ab9afe34fdbbfbd3a4",
              "IPY_MODEL_bfa97c3017e849d1b84180bc9902aaab",
              "IPY_MODEL_bb2a394a599a4d36be18ca1fe6312a4f"
            ],
            "layout": "IPY_MODEL_60788aaa6c814addbd209cd07f54be03"
          }
        },
        "92efff39bde945ab9afe34fdbbfbd3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ca046e033b48b898944d6e76a693a1",
            "placeholder": "​",
            "style": "IPY_MODEL_45bdcb3cccb743aa914c6c83c652c0b3",
            "value": "  0%"
          }
        },
        "bfa97c3017e849d1b84180bc9902aaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cee12b7765446a18df588b206b15892",
            "max": 34,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a98270559894096a3f18986345167d4",
            "value": 0
          }
        },
        "bb2a394a599a4d36be18ca1fe6312a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07f95396f3b498d9773dfeb81819493",
            "placeholder": "​",
            "style": "IPY_MODEL_e1584818d67844058017788e1f70605e",
            "value": " 0/34 [00:00&lt;?, ?it/s]"
          }
        },
        "60788aaa6c814addbd209cd07f54be03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ca046e033b48b898944d6e76a693a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45bdcb3cccb743aa914c6c83c652c0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cee12b7765446a18df588b206b15892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a98270559894096a3f18986345167d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d07f95396f3b498d9773dfeb81819493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1584818d67844058017788e1f70605e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}