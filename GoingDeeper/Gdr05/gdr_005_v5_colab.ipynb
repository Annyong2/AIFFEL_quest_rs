{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7b33228d",
      "metadata": {
        "id": "7b33228d"
      },
      "source": [
        "### ì½”ë”ì˜ ì†ŒíšŒ :\n",
        "ë‚ ì”¨ : ì˜¤ëŠ˜ì˜ í•™ìŠµ < ë³´í†µâ˜ï¸>í–ˆìŠµë‹ˆë‹¤. [â˜€ï¸â›…â˜ï¸ğŸŒ§ï¸ğŸŒ©ï¸â›ˆï¸]\n",
        "- ë°°ìš´ì  : ì§„í–‰í•˜ê³ ìí•˜ëŠ” í›ˆë ¨ì— ê¼­! ê¸° ì›í•˜ëŠ” ì˜µì…˜ì´ ìˆë‹¤ë©´ ëª¨ë¸ ì„¤ê³„ë•Œ ëª¨ë¸ êµ¬ì„±ìš”ì†Œ(ex.ì˜µí‹°ë§ˆì´ì €ì € ë“±)ì— **í•´ë‹¹ ê¸°ëŠ¥ì„ ì§€ì›í•˜ëŠ”ê°€**, ì§€ì›í•˜ì§€ ì•Šìœ¼ë©´ ë‹¤ë¥¸ ë¹„ìŠ·í•œ ëŒ€ì•ˆì´ ìˆëŠ”ê°€ ì•Œì•„ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤.\n",
        "- ì•„ì‰¬ìš´ì  : Matrixê¹Œì§€ ì‹¤í–‰í•˜ì§€ ëª»í•˜ì˜€ë˜ê²Œ ì•„ì‰½ìŠµë‹ˆë‹¤. ì—‰ëš±í•œ ê³³(íŒŒì¼ ì••ì¶•í•´ì œ í•¨ìˆ˜í™”)ì—ì„œ ì˜¤ì „ ì‹œê°„ì„ ë‹¤ ì‚¬ìš©í•œ ê²ƒì´ ì•„ì‰½ìŠµë‹ˆë‹¤. ì˜ë²ˆì—­ê¹Œì§€ í•´ë³´ê³ ì‹¶ìŠµë‹ˆë‹¤.  \n",
        "- ëŠë‚€ì  :  \n",
        "\n",
        "(ì°¸ê³  : https://github.com/Annyong2/AIFFEL_quest_rs/tree/master/GoingDeeper/Gdr05)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37ccd71b",
      "metadata": {
        "id": "37ccd71b"
      },
      "source": [
        "### ì „ì²´ ì½”ë“œ ì‹¤í–‰ í”Œë¡œìš° (ëª©ì°¨):\n",
        "\n",
        "**STEP 1. ë¶ˆëŸ¬ì˜¤ê¸° : ë¼ì´ë¸ŒëŸ¬ë¦¬ & ë°ì´í„°**  \n",
        "\n",
        "**STEP 2. ë°ì´í„° ì •ì œ ë° í† í°í™”**  \n",
        "\n",
        "**STEP 3. ëª¨ë¸ ì„¤ê³„**  \n",
        "\n",
        "**STEP 4. ëª¨ë¸ í›ˆë ¨**  \n",
        "\n",
        "**STEP 5. ë²ˆì—­ ë° ì‹œê°í™”**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b46bb90f",
      "metadata": {
        "id": "b46bb90f"
      },
      "source": [
        "**[TIP] STEP 4. ëª¨ë¸ ì„¤ê³„**\n",
        "- í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ì˜ ë²ˆì—­í•´ ì¤„ ë©‹ì§„ Attention ê¸°ë°˜ Seq2seq ëª¨ë¸ì„ ì„¤ê³„í•˜ì„¸ìš”!\n",
        "- ì•ì„œ ë§Œë“  ëª¨ë¸ì— Dropout ëª¨ë“ˆì„ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§‘ë‹ˆë‹¤!\n",
        "- Embedding Sizeì™€ Hidden SizeëŠ” ì‹¤í—˜ì„ í†µí•´ ì ë‹¹í•œ ê°’ì„ ë§ì¶° ì£¼ë„ë¡ í•©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8d9fdc",
      "metadata": {
        "id": "8b8d9fdc"
      },
      "source": [
        "**[TIP] STEP 5. ëª¨ë¸ í›ˆë ¨**  \n",
        "- traing loss ì•ˆì •ì ìœ¼ë¡œ ë–¨ì–´ì§€ë©´ì„œ í•™ìŠµ ì§„í–‰  \n",
        "  \n",
        "**[TIP] STEP 6. ëª¨ë¸ í‰ê°€(í…ŒìŠ¤íŠ¸)**  \n",
        "- ë°ìŠ¤íŠ¸ìš© ë””ì½”ë” ëª¨ë¸ì˜ ì¶œë ¥ ê²°ê³¼ê°€ ì •ë‹µê³¼ ì–´ëŠ ì •ë„ ìœ ì‚¬í•œ ì˜ë²ˆì—­ ì§„í–‰"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31ae222",
      "metadata": {
        "id": "b31ae222"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55e1234d",
      "metadata": {
        "id": "55e1234d"
      },
      "source": [
        "# STEP 1. ë¶ˆëŸ¬ì˜¤ê¸° : ë¼ì´ë¸ŒëŸ¬ë¦¬ & ë°ì´í„°   \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5e35d20",
      "metadata": {
        "id": "c5e35d20"
      },
      "source": [
        "### 1.1 ë¼ì´ë¸ŒëŸ¬ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "aa696ce3",
      "metadata": {
        "id": "aa696ce3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "import os\n",
        "import sentencepiece as spm\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm  # í°íŠ¸ ì„¤ì •\n",
        "\n",
        "\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "\n",
        "import seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d3cb0079",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cb0079",
        "outputId": "d6595baa-f69a-4790-d9ce-5feb13f84105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# í•œê¸€ì„¤ì •\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "mpl.font_manager.findfont(font)\n",
        "\n",
        "print(\"ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7agOfILkfaL",
        "outputId": "923d5514-2198-490c-b80e-0090342ced41"
      },
      "id": "Q7agOfILkfaL",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3baf27b3",
      "metadata": {
        "id": "3baf27b3"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ ì €ì¥ê²½ë¡œ\n",
        "# data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
        "kor_path = '/content/drive/MyDrive/camp/korean-english-park.train.ko' # data_dir+\"/korean-english-park.train.ko\"\n",
        "eng_path = '/content/drive/MyDrive/camp/korean-english-park.train.en' # data_dir+\"/korean-english-park.train.en\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b739a233",
      "metadata": {
        "id": "b739a233"
      },
      "source": [
        "### ë°ì´í„° í™•ì¸"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a34b7c",
      "metadata": {
        "id": "c9a34b7c"
      },
      "source": [
        "ë°ì´í„° ì¶œì²˜ : https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f5a10d",
      "metadata": {
        "id": "05f5a10d"
      },
      "source": [
        "#### 1.3 ë°ì´í„° í™•ì¸ : TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "7dac6ea9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dac6ea9",
        "outputId": "9cd51047-3836-4461-e32a-32899f027860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> ê°œì¸ìš© ì»´í“¨í„° ì‚¬ìš©ì˜ ìƒë‹¹ ë¶€ë¶„ì€ \"ì´ê²ƒë³´ë‹¤ ë›°ì–´ë‚  ìˆ˜ ìˆëŠëƒ?\"\n",
            ">> ë¶í•œì˜ í•µë¬´ê¸° ê³„íšì„ í¬ê¸°í•˜ë„ë¡ í•˜ë ¤ëŠ” ì••ë ¥ì´ ê±°ì„¸ì§€ê³  ìˆëŠ” ê°€ìš´ë°, ì¼ë³¸ê³¼ ë¶í•œì˜ ì™¸êµê´€ë“¤ì´ ì™¸êµ ê´€ê³„ë¥¼ ì •ìƒí™”í•˜ë ¤ëŠ” íšŒë‹´ì„ ì¬ê°œí–ˆë‹¤.\n",
            ">> \"ê²½í˜¸ ë¡œë³´íŠ¸ê°€ ì¹¨ì…ìë‚˜ í™”ì¬ë¥¼ íƒì§€í•˜ê¸° ìœ„í•´ì„œ ê°œì¸ì ìœ¼ë¡œ, ê·¸ë¦¬ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
            ">> ìˆ˜ìì›ë¶€ ë‹¹êµ­ì€ ë…¼ë€ì´ ë˜ê³  ìˆê³ , ë§‰ëŒ€í•œ ë¹„ìš©ì´ ë“œëŠ” ì´ ì‚¬ì—…ì— ëŒ€í•´ ë‚´ë…„ì— ê±´ì„¤ì„ ì‹œì‘í•  ê³„íšì´ë‹¤.\n",
            ">> ë˜í•œ ê·¼ë ¥ ìš´ë™ì€ í™œë°œí•˜ê²Œ ê±·ëŠ” ê²ƒì´ë‚˜ ìµœì†Œí•œ 20ë¶„ ë™ì•ˆ ë›°ëŠ” ê²ƒê³¼ ê°™ì€ ìœ ì‚°ì†Œ í™œë™ì—ì„œ ì–»ëŠ” ìš´ë™ íš¨ê³¼ë¥¼ ì‹¬ì¥ê³¼ íì— ì£¼ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì—°êµ¬í•™ìë“¤ì€ ê·¼ë ¥ ìš´ë™ì´ ì‹¬ì¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì—¬ë¶€ì— ëŒ€í•´ ë…¼ìŸì„ í•´ì™”ë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# KOREAN\n",
        "# ë°ì´í„° í˜•íƒœ í™•ì¸\n",
        "with open(kor_path, \"r\") as f:\n",
        "    raw_ko = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_ko))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen_ko in raw_ko[0:100][::20]: print(\">>\", sen_ko)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "09ba9ac4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ba9ac4",
        "outputId": "5ab92c84-1d21-48d1-cf4d-bfe5d0dfad0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> Much of personal computing is about \"can you top this?\"\n",
            ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
            ">> â€œGuard robots are used privately and professionally to detect intruders or fire,â€ Karlsson said.\n",
            ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
            ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
          ]
        }
      ],
      "source": [
        "# ENGLISH\n",
        "# ë°ì´í„° í˜•íƒœ í™•ì¸\n",
        "with open(eng_path, \"r\") as f:\n",
        "    raw_en = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_en))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen_en in raw_en[0:100][::20]: print(\">>\", sen_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "499d98d8",
      "metadata": {
        "id": "499d98d8"
      },
      "source": [
        "##### ì½”ë©˜íŠ¸:\n",
        "í•œêµ­ì–´ë°ì´í„°ì™€ ì˜ì–´ë°ì´í„° í¬ê¸°ê°€ ë™ì¼í•˜ë‹¤.    \n",
        "ë‘ íŒŒì¼ë¡œ ë‚˜ëˆ ì ¸ìˆëŠ” ë°ì´í„°ë“¤ì€ ìˆœì„œ(idx)ë„ ë§¤í•‘ë˜ì–´ìˆë‹¤.(raw_ko[1] = raw_en[1])      \n",
        "=> ë³‘ë ¬ë¡œ ë¬¶ëŠ”ë‹¤"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d042d192",
      "metadata": {
        "id": "d042d192"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7204b527",
      "metadata": {
        "id": "7204b527"
      },
      "source": [
        "# Step 2. ë°ì´í„° ì •ì œ ë° í† í°í™”   \n",
        "\n",
        "2.1 ë°ì´í„° ì •ì œ  \n",
        "2.2 ë°ì´í„° í† í°í™”  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd08979c",
      "metadata": {
        "id": "bd08979c"
      },
      "source": [
        "### 2.1.1 ë°ì´í„° ì •ì œ : ë³‘ë ¬ ë°ì´í„°ì…‹ ìƒì„± ë° ì¤‘ë³µì œê±°(set()ì‚¬ìš©)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "4749410f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4749410f",
        "outputId": "3ea1bc9b-cfc3-4082-dcdb-7af325a7f3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë³‘ë ¬ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ\n",
            "ë³‘ë ¬ ë°ì´í„°ì…‹ ì¤‘ë³µì œê±° ì™„ë£Œ : 94123 ->78968 \n",
            "\n",
            "Type(cleaned_corpus) :  <class 'list'> \n",
            " [('ê°¤ëŸ½ ì—¬ë¡ ì¡°ì‚¬ëŠ” 1930ë…„ëŒ€ë¶€í„° ì‹¤ì‹œëì§€ë§Œ ëŒ€í†µë ¹ì— ëŒ€í•œ ì§€ì§€ìœ¨ì„ ì›”ë³„ë¡œ ë°œí‘œí•œ ê²ƒì€ íŠ¸ë£¨ë¨¼ ì‹œëŒ€ë¶€í„°ë‹¤.', \"While Gallup polling goes back to the 1930s, it wasn't until the Truman years that they began surveying monthly approval ratings.\")]\n"
          ]
        }
      ],
      "source": [
        "def clean_corpus(kor_path, eng_path):\n",
        "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
        "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
        "    assert len(kor) == len(eng)\n",
        "\n",
        "    dataset = list(zip(kor, eng))\n",
        "    print(\"ë³‘ë ¬ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ\")\n",
        "    cleaned_corpus = list(set(dataset))\n",
        "    print(f\"ë³‘ë ¬ ë°ì´í„°ì…‹ ì¤‘ë³µì œê±° ì™„ë£Œ : {len(dataset)} ->{len(cleaned_corpus)}\",\"\\n\")\n",
        "    ko_corpus, en_corpus = zip(*cleaned_corpus)\n",
        "\n",
        "    return cleaned_corpus, ko_corpus, en_corpus\n",
        "\n",
        "\n",
        "cleaned_corpus, ko_corpus, en_corpus = clean_corpus(kor_path, eng_path)\n",
        "\n",
        "print(\"Type(cleaned_corpus) : \", type(cleaned_corpus),\"\\n\",cleaned_corpus[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dcffccd",
      "metadata": {
        "id": "6dcffccd"
      },
      "source": [
        "##### ì¤‘ë³µì œê±° í›„ ì½”ë©˜íŠ¸ :\n",
        "\n",
        "\n",
        "ì˜í•œ ë°ì´í„°ë¥¼ ë³‘ë ¬êµ¬ì¡°ë¡œ ë§Œë“¤ê³ , set()ë§¤ì¨ë“œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µì œê±°ë¥¼ í•˜ì˜€ë‹¤.  \n",
        "\n",
        "ë°ì´í„° ì¤‘ë³µ ì œê±°í›„, ë°ì´í„°ëŠ” ì´ì „ì˜ 80%(94123 ->78968)ì •ë„ ë‚¨ì•˜ë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd54780d",
      "metadata": {
        "id": "dd54780d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73570d0",
      "metadata": {
        "id": "e73570d0"
      },
      "source": [
        "### 2.1.2 ë°ì´í„° ì •ì œ : ë°ì´í„° ì „ì²˜ë¦¬ (lms 4ê°€ì§€ ë°˜ì˜ ì™„ë£Œ)\n",
        "- ëª¨ë“  ì…ë ¥ì„ ì†Œë¬¸ìë¡œ ë³€í™˜\n",
        "- ì•ŒíŒŒë²³, ë¬¸ì¥ë¶€í˜¸, í•œê¸€ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°\n",
        "- ë¬¸ì¥ë¶€í˜¸ ì–‘ì˜†ì— ê³µë°±ì„ ì¶”ê°€\n",
        "- ë¬¸ì¥ ì•ë’¤ì˜ ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì œê±°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e561e4f",
      "metadata": {
        "id": "2e561e4f"
      },
      "source": [
        "##### ì „ì²˜ë¦¬ í•¨ìˆ˜ preprocess_sentence ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "7b3a11bd",
      "metadata": {
        "id": "7b3a11bd"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    # 1. ì†Œë¬¸ì ë³€í™˜\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # 2. ì•ŒíŒŒë²³, ë¬¸ì¥ë¶€í˜¸, í•œê¸€ ì™¸ ì œê±°\n",
        "    sentence = re.sub(r'\\d', '', sentence)\n",
        "\n",
        "    # 3. ë¬¸ì¥ë¶€í˜¸ ì–‘ì˜† ê³µë°± ì¶”ê°€\n",
        "    sentence = re.sub(r'(\\W)', r' \\1 ', sentence)\n",
        "\n",
        "    # 4. ë¬¸ì¥ ì•ë’¤ ê³µë°± ì œê±°\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    # 5. ì¤‘ë³µëœ ê³µë°± ì œê±°\n",
        "    # sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7d0ebef",
      "metadata": {
        "id": "b7d0ebef"
      },
      "source": [
        "##### ì „ì²˜ë¦¬ í•¨ìˆ˜ preprocess_sentenceì‘ë™ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "6f80e0dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f80e0dc",
        "outputId": "398bf184-4b97-4146-fa99-a3c6b9b080cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¯¸í•˜ì¼ ì¹´ë¯¸ë‹Œ ëŸ¬ì‹œì•„ ì™¸ë¬´ë¶€ ëŒ€ë³€ì¸ì€ ê¸°ìíšŒê²¬ì—ì„œ â€œëŸ¬ì‹œì•„ê°€ 19ì¼ 4ëª…ì˜ ì˜êµ­ ì™¸êµê´€ì„ ì¶”ë°©í•œ ê²ƒì€ ì˜êµ­ ì •ë¶€ê°€ ì·¨í•œ ì¡°ì¹˜ì— ëŒ€í•œ ë°˜ì‘ì´ë‹¤â€ë¼ê³  ë°œí‘œí–ˆë‹¤.\n",
            "ë¯¸í•˜ì¼   ì¹´ë¯¸ë‹Œ   ëŸ¬ì‹œì•„   ì™¸ë¬´ë¶€   ëŒ€ë³€ì¸ì€   ê¸°ìíšŒê²¬ì—ì„œ    â€œ ëŸ¬ì‹œì•„ê°€   ì¼   ëª…ì˜   ì˜êµ­   ì™¸êµê´€ì„   ì¶”ë°©í•œ   ê²ƒì€   ì˜êµ­   ì •ë¶€ê°€   ì·¨í•œ   ì¡°ì¹˜ì—   ëŒ€í•œ   ë°˜ì‘ì´ë‹¤ â€ ë¼ê³    ë°œí‘œí–ˆë‹¤ .\n"
          ]
        }
      ],
      "source": [
        "# í™•ì¸\n",
        "text = 'ë¯¸í•˜ì¼ ì¹´ë¯¸ë‹Œ ëŸ¬ì‹œì•„ ì™¸ë¬´ë¶€ ëŒ€ë³€ì¸ì€ ê¸°ìíšŒê²¬ì—ì„œ â€œëŸ¬ì‹œì•„ê°€ 19ì¼ 4ëª…ì˜ ì˜êµ­ ì™¸êµê´€ì„ ì¶”ë°©í•œ ê²ƒì€ ì˜êµ­ ì •ë¶€ê°€ ì·¨í•œ ì¡°ì¹˜ì— ëŒ€í•œ ë°˜ì‘ì´ë‹¤â€ë¼ê³  ë°œí‘œí–ˆë‹¤.'\n",
        "print(text)\n",
        "print(preprocess_sentence(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd9edba",
      "metadata": {
        "id": "4dd9edba"
      },
      "source": [
        "### 2.2.1 ë°ì´í„° í† í°í™”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df18ea04",
      "metadata": {
        "id": "df18ea04"
      },
      "source": [
        "##### í† í°í™” í•¨ìˆ˜ generate_tokenizer ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a2008ec5",
      "metadata": {
        "id": "a2008ec5"
      },
      "outputs": [],
      "source": [
        "# Sentencepieceë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµí•œ tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "# ì½”í¼ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  SentencePieceì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •\n",
        "def save_corpus(corpus, filepath):\n",
        "    with open(filepath, 'w') as f:\n",
        "        for line in corpus:\n",
        "            f.write(f\"{line}\\n\")\n",
        "\n",
        "# SentencePieceì—ì„œ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "def generate_tokenizer(corpus,\n",
        "                       vocab_size,\n",
        "                       lang=\"ko\",\n",
        "                       pad_id=0,\n",
        "                       bos_id=1,\n",
        "                       eos_id=2,\n",
        "                       unk_id=3):\n",
        "    corpus_file = f\"{lang}_corpus.txt\"\n",
        "    save_corpus(corpus, corpus_file)\n",
        "\n",
        "    # SentencePiece í•™ìŠµ ì‹œ ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜ ì¶”ê°€\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=corpus_file,\n",
        "        model_prefix=f\"{lang}_tokenizer\",\n",
        "        vocab_size=vocab_size,\n",
        "        pad_id=pad_id,\n",
        "        bos_id=bos_id,\n",
        "        eos_id=eos_id,\n",
        "        unk_id=unk_id,\n",
        "        num_threads=4  # ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜ ì¶”ê°€\n",
        "    )\n",
        "\n",
        "    # í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    tokenizer = spm.SentencePieceProcessor()\n",
        "    tokenizer.Load(f\"{lang}_tokenizer.model\")\n",
        "\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b78430",
      "metadata": {
        "id": "24b78430"
      },
      "source": [
        "##### ì „ì²˜ë¦¬í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "21acc024",
      "metadata": {
        "id": "21acc024"
      },
      "outputs": [],
      "source": [
        "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
        "\n",
        "N = len(cleaned_corpus)\n",
        "kor_corpus = []\n",
        "eng_corpus = []\n",
        "for i in range(N):\n",
        "    kor_corpus.append(preprocess_sentence(ko_corpus[i]))\n",
        "    eng_corpus.append(preprocess_sentence(en_corpus[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ca68bf79",
      "metadata": {
        "id": "ca68bf79"
      },
      "outputs": [],
      "source": [
        "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "85fc8a6f",
      "metadata": {
        "id": "85fc8a6f"
      },
      "outputs": [],
      "source": [
        "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "952cfb8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "952cfb8f",
        "outputId": "fdfee161-5926-4324-f7eb-1d61d70ed628"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "79094d7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "912b023c63d14a44a74225ca50d5189f",
            "b9d71bbbd03342cdb536efa482d98bcb",
            "5356b1fff7344b5691d8340249a93748",
            "4670bef805c6415aa608ccc7b4e1fd44",
            "824ee3fd77d545c6a26bd1bd4eab58d8",
            "b3a24bdb32fa42c7876bd1acf998e212",
            "4677e172b82d430a84f11efce50f2285",
            "f1b98ee40f8d41f29a354758e32bad6d",
            "c23d51bf17c641aba9d03d7b66374186",
            "97270071a3c6451aa511c927b319a6bd",
            "399c9d7fc11045d3b7dfae948de01122"
          ]
        },
        "id": "79094d7c",
        "outputId": "7c63f10b-25a3-4d57-8189-b0d352ec512e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/78968 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "912b023c63d14a44a74225ca50d5189f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2151\n",
            "2151\n"
          ]
        }
      ],
      "source": [
        "src_corpus = []\n",
        "tgt_corpus = []\n",
        "\n",
        "assert len(kor_corpus) == len(eng_corpus)\n",
        "\n",
        "# í† í°ì˜ ê¸¸ì´ê°€ 50 ì´í•˜ì¸ ë¬¸ì¥ë§Œ ë‚¨ê¹ë‹ˆë‹¤.\n",
        "for idx in tqdm(range(len(kor_corpus))):\n",
        "    if len(kor_corpus[idx]) <= 50 and len(eng_corpus[idx]) <= 50:  # len(kor_corpus[idx]) <= 50:\n",
        "        src_corpus.append(kor_corpus[idx])\n",
        "        tgt_corpus.append(eng_corpus[idx])\n",
        "    else :\n",
        "        pass\n",
        "\n",
        "print(len(src_corpus))\n",
        "print(len(tgt_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d6af689b",
      "metadata": {
        "id": "d6af689b"
      },
      "outputs": [],
      "source": [
        "# ko_tokenizerì™€ en_tokenizerë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\n",
        "src_corpus_tokenized = [ko_tokenizer.encode_as_ids(sentence) for sentence in src_corpus]\n",
        "tgt_corpus_tokenized = [en_tokenizer.encode_as_ids(sentence) for sentence in tgt_corpus]\n",
        "\n",
        "# íŒ¨ë”©ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ì—¬ í•™ìŠµìš© ë°ì´í„°ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.\n",
        "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus_tokenized, padding='post')\n",
        "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus_tokenized, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e73d16e",
      "metadata": {
        "id": "7e73d16e"
      },
      "source": [
        "ğŸ‘ï¸ğŸ‘ï¸**ì½”ë©˜íŠ¸ :**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ad4125",
      "metadata": {
        "id": "40ad4125"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e5f7ec1",
      "metadata": {
        "id": "7e5f7ec1"
      },
      "source": [
        "# STEP 3. ëª¨ë¸ ì„¤ê³„  \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "f46fd2f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46fd2f8",
        "outputId": "fb6c63bc-154e-4872-9b2f-4b69a3c66a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class PoswiseFeedForwardNet, return out\n",
            "class MultiHeadAttention, return out, attention_weights\n",
            "class EncoderLayer, return out, enc_attn\n",
            "ìŠ=3\n",
            "class Encoder, return out, enc_attns\n",
            "class Decoder, return out, dec_attns, dec_enc_attns\n"
          ]
        }
      ],
      "source": [
        "## PositionalEncoding\n",
        "## ìš©ë„ : ì…ë ¥ ìœ„ì¹˜ì— ë”°ë¼ ìœ„ì¹˜ ì¸ì½”ë”© ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "def PositionalEncoding(pos, d_model):\n",
        "    def cal_angle(position, i):\n",
        "        return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "    return sinusoid_table\n",
        "\n",
        "print(\"class PoswiseFeedForwardNet, return out\")\n",
        "\n",
        "\n",
        "## MultiHeadAttention\n",
        "## ìš©ë„ : ì…ë ¥ì— ëŒ€í•œ ì—¬ëŸ¬ í—¤ë“œì˜ ì–´í…ì…˜ì„ ê³„ì‚°í•˜ì—¬ ê²°í•©í•©ë‹ˆë‹¤.\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        # Linear Layers for Q, K, V\n",
        "        self.W_q = tf.keras.layers.Dense(d_model)\n",
        "        self.W_k = tf.keras.layers.Dense(d_model)\n",
        "        self.W_v = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        # Output linear layer\n",
        "        self.linear = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "\n",
        "        # Scaled QK^T / sqrt(d_k)\n",
        "        scaled_qk = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(d_k)\n",
        "\n",
        "        # Add the mask to the scaled tensor\n",
        "        if mask is not None:\n",
        "            scaled_qk += (mask * -1e9)\n",
        "\n",
        "        # Softmax over the last axis to get attention weights\n",
        "        attention_weights = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "\n",
        "        # Multiply the attention weights by the values\n",
        "        out = tf.matmul(attention_weights, V)\n",
        "\n",
        "        return out, attention_weights\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Split the embedding into num_heads for parallel processing\n",
        "        batch_size = x.shape(x)[0]\n",
        "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        split_x = tf.transpose(x, perm=[0, 2, 1, 3])  # [batch, heads, length, depth]\n",
        "        return split_x\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine the split heads back into the original shape\n",
        "        batch_size = x.shape(x)[0]\n",
        "        combine_heads_x = tf.transpose(x, perm=[0, 2, 1, 3])  # [batch, length, heads, depth]\n",
        "        combine_heads_x = tf.reshape(x, (batch_size, -1, self.d_model))\n",
        "        return combine_heads_x\n",
        "\n",
        "    def call(self, Q, K, V, mask):\n",
        "        # Step 1: Linear transformation for Q, K, V\n",
        "        WQ = self.W_q(Q)\n",
        "        WK = self.W_k(K)\n",
        "        WV = self.W_v(V)\n",
        "\n",
        "        # Step 2: Split heads\n",
        "        WQ_split = self.split_heads(WQ)\n",
        "        WK_split = self.split_heads(WK)\n",
        "        WV_split = self.split_heads(WV)\n",
        "\n",
        "        # Step 3: Scaled Dot-Product Attention\n",
        "        out, attention_weights = self.scaled_dot_product_attention(\n",
        "            WQ_split, WK_split, WV_split, mask)\n",
        "\n",
        "        # Step 4: Combine heads\n",
        "        out = self.combine_heads(out)\n",
        "\n",
        "        # Step 5: Final linear layer\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out, attention_weights\n",
        "\n",
        "\n",
        "## PoswiseFeedForwardNet\n",
        "## ìš©ë„ : ê° ìœ„ì¹˜ë³„ë¡œ ì™„ì „ ì—°ê²° ì‹ ê²½ë§ì„ ì ìš©í•˜ì—¬ ë¹„ì„ í˜• ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.w_1(x)\n",
        "        out = self.w_2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"class MultiHeadAttention, return out, attention_weights\")\n",
        "\n",
        "## EncoderLayer\n",
        "## ìš©ë„ : ì…ë ¥ì„ ì¸ì½”ë”ì— ì „ë‹¬í•˜ì—¬ ì–´í…ì…˜ ë° í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, enc_attn\n",
        "\n",
        "print(\"class EncoderLayer, return out, enc_attn\")\n",
        "\n",
        "## DecoderLayer\n",
        "## ìš©ë„ : ì…ë ¥ì„ ë””ì½”ë”ì— ì „ë‹¬í•˜ì—¬ ì–´í…ì…˜ ë° í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "# DecoderLayer í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.dec_mask_attn = MultiHeadAttention(d_model, n_heads)  # Masked Attention\n",
        "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)  # Encoder-Decoder Attention\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        # Layer Normalization ì¶”ê°€\n",
        "        self.norm_0 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        \"\"\"\n",
        "        Masked Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x  # Residual connection ì„¤ì •\n",
        "        out = self.norm_0(x)  # ì…ë ¥ ì •ê·œí™”\n",
        "        out, mask_attn = self.dec_mask_attn(out, out, out, causality_mask)  # causality_mask ì‚¬ìš©\n",
        "        out = self.dropout(out)\n",
        "        out += residual  # Residual connection ì ìš©\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention (Encoder-Decoder Attention)\n",
        "        \"\"\"\n",
        "        residual = out  # ì—¬ê¸°ì„œ xê°€ ì•„ë‹ˆë¼ outì„ residualë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "        out = self.norm_1(out)  # ì•ì—ì„œ ë‚˜ì˜¨ outì„ ì •ê·œí™”\n",
        "        out, dec_attn = self.dec_self_attn(out, enc_out, enc_out, padding_mask)  # padding_mask ì‚¬ìš©\n",
        "        out = self.dropout(out)\n",
        "        out += residual  # Residual connection ì ìš©\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out  # Feed Forward ì „ì—ë„ residualì„ ì„¤ì •í•´ì•¼ í•¨\n",
        "        out = self.norm_2(out)  # ì •ê·œí™”\n",
        "        out = self.ffn(out)  # Feed Forward Network ì ìš©\n",
        "        out = self.dropout(out)\n",
        "        out += residual  # Residual connection ì ìš©\n",
        "\n",
        "        return out, mask_attn, dec_attn  # Masked Self-Attentionê³¼ Encoder-Decoder Attentionì˜ ê²°ê³¼ ë°˜í™˜\n",
        "\n",
        "print(\"ìŠ=3\")\n",
        "\n",
        "\n",
        "## Encoder\n",
        "## ìš©ë„ : ì—¬ëŸ¬ ê°œì˜ ì¸ì½”ë” ë ˆì´ì–´ë¥¼ ìŒ“ì•„ ì „ì²´ ì¸ì½”ë”ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                        for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        out = x\n",
        "\n",
        "        enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, enc_attn = self.enc_layers[i](out, mask)\n",
        "            enc_attns.append(enc_attn)\n",
        "\n",
        "        return out, enc_attns\n",
        "\n",
        "print(\"class Encoder, return out, enc_attns\")\n",
        "\n",
        "## Decoder\n",
        "## ìš©ë„ : ì—¬ëŸ¬ ê°œì˜ ë””ì½”ë” ë ˆì´ì–´ë¥¼ ìŒ“ì•„ ì „ì²´ ë””ì½”ë”ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                            for _ in range(n_layers)]\n",
        "\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        out = x\n",
        "\n",
        "        dec_attns = list()\n",
        "        dec_enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, dec_attn, dec_enc_attn = \\\n",
        "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "            dec_attns.append(dec_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "        return out, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"class Decoder, return out, dec_attns, dec_enc_attns\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer\n",
        "## ìš©ë„ : ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ê²°í•©í•˜ì—¬ ì „ì²´ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 src_vocab_size,\n",
        "                 tgt_vocab_size,\n",
        "                 pos_len,\n",
        "                 dropout=0.2,\n",
        "                 shared=False):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.shared = shared\n",
        "\n",
        "        # 1. Embedding Layer ì •ì˜\n",
        "        self.src_embedding = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # 2. Positional Encoding ì •ì˜\n",
        "        self.pos_encoding = PositionalEncoding(pos_len, d_model)\n",
        "        # 6. Dropout ì •ì˜\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        # 3. Encoder / Decoder ì •ì˜\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        # 4. Output Linear ì •ì˜\n",
        "        self.out_linear = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "        self.shared = shared\n",
        "\n",
        "        # 5. Shared Weights\n",
        "        if shared: self.out_linear.set_weights(tf.transpose(self.tgt_embedding.weights))\n",
        "\n",
        "\n",
        "    def embedding(self, emb, x):\n",
        "        seq_len = x.shape[1]\n",
        "        out = emb(x)\n",
        "\n",
        "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "        out = self.dropout(out)\n",
        "\n",
        "\n",
        "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "        \"\"\"\n",
        "        ìˆœì„œì— ë”°ë¼ Encoder, Decoder, ê·¸ë¦¬ê³  Output ê³„ì‚°\n",
        "        \"\"\"\n",
        "        enc_in = self.embedding(self.src_embedding, enc_in)\n",
        "        dec_in = self.embedding(self.tgt_embedding, dec_in)\n",
        "\n",
        "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "\n",
        "        dec_out, dec_attns, dec_enc_attns = \\\n",
        "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "\n",
        "        # Step 4: Out Linear(dec_out)\n",
        "        logits = self.out_linear(dec_out)\n",
        "\n",
        "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"Transformer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqYMyJNEyWyZ",
        "outputId": "2aca9057-ecb7-4763-b6d8-35c2da3e0560"
      },
      "id": "GqYMyJNEyWyZ",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64884fe0",
      "metadata": {
        "id": "64884fe0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803d6c43",
      "metadata": {
        "id": "803d6c43"
      },
      "source": [
        "# STEP 4. ëª¨ë¸ í›ˆë ¨\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "c7b5e084",
      "metadata": {
        "id": "c7b5e084"
      },
      "outputs": [],
      "source": [
        "def generate_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "'''\n",
        "def generate_causality_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "'''\n",
        "# generate_causality_mask í•¨ìˆ˜ ìˆ˜ì •\n",
        "def generate_causality_mask(tgt):\n",
        "    size = tf.shape(tgt)[1]  # ì‹œí€€ìŠ¤ ê¸¸ì´ ì¶”ì¶œ\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def generate_masks(src, tgt):\n",
        "    enc_mask = generate_padding_mask(src)\n",
        "    dec_mask = generate_causality_mask(tgt)\n",
        "    dec_enc_mask = generate_padding_mask(tgt)\n",
        "\n",
        "    return enc_mask, dec_enc_mask, dec_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "300ce39c",
      "metadata": {
        "id": "300ce39c"
      },
      "outputs": [],
      "source": [
        "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(LearningRateScheduler, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = step ** -0.5\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "4ba81c9d",
      "metadata": {
        "scrolled": true,
        "id": "4ba81c9d"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(n_layers=2,\n",
        "                          d_model=512,\n",
        "                          n_heads=8,\n",
        "                          d_ff=2048,\n",
        "                          src_vocab_size=SRC_VOCAB_SIZE,\n",
        "                          tgt_vocab_size=TGT_VOCAB_SIZE,\n",
        "                          pos_len=50,\n",
        "                          shared=True\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "2116b111",
      "metadata": {
        "id": "2116b111"
      },
      "outputs": [],
      "source": [
        "learning_rate = LearningRateScheduler(512.0)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "e603b998",
      "metadata": {
        "id": "e603b998"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    # Masking ë˜ì§€ ì•Šì€ ì…ë ¥ì˜ ê°œìˆ˜ë¡œ Scalingí•˜ëŠ” ê³¼ì •\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "cc5e934f",
      "metadata": {
        "id": "cc5e934f"
      },
      "outputs": [],
      "source": [
        "@tf.function()\n",
        "def train_step(src, tgt, model, optimizer):\n",
        "    gold = tgt[:, 1:]\n",
        "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # predictions ê³„ì‚°ì„ tape ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ìˆ˜í–‰í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
        "        loss = loss_function(gold, predictions[:, :-1])\n",
        "\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # tf.functionì—ì„œ ê°’ë“¤ì„ ì œëŒ€ë¡œ ìº¡ì²˜í•˜ë„ë¡ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "    return {'loss': loss, 'enc_attns': enc_attns, 'dec_attns': dec_attns, 'dec_enc_attns': dec_enc_attns}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2f749c",
      "metadata": {
        "id": "de2f749c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7affabb",
      "metadata": {
        "id": "e7affabb"
      },
      "source": [
        "# STEP 5. ë²ˆì—­ ë° ì‹œê°í™”  \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "ab4d7fb4",
      "metadata": {
        "id": "ab4d7fb4"
      },
      "outputs": [],
      "source": [
        "# ë²ˆì—­ ìƒì„± í•¨ìˆ˜\n",
        "\n",
        "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
        "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
        "\n",
        "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    ids = []\n",
        "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
        "    for i in range(dec_train.shape[-1]):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
        "        generate_masks(_input, output)\n",
        "\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
        "        model(_input,\n",
        "              output,\n",
        "              enc_padding_mask,\n",
        "              combined_mask,\n",
        "              dec_padding_mask)\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
        "\n",
        "        if tgt_tokenizer.eos_id() == predicted_id:\n",
        "            result = tgt_tokenizer.decode_ids(ids)\n",
        "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "        ids.append(predicted_id)\n",
        "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
        "\n",
        "    result = tgt_tokenizer.decode_ids(ids)\n",
        "\n",
        "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "bf99240a",
      "metadata": {
        "id": "bf99240a"
      },
      "outputs": [],
      "source": [
        "# Attention ì‹œê°í™” í•¨ìˆ˜\n",
        "\n",
        "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
        "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
        "        import seaborn\n",
        "        seaborn.heatmap(data,\n",
        "                        square=True,\n",
        "                        vmin=0.0, vmax=1.0,\n",
        "                        cbar=False, ax=ax,\n",
        "                        xticklabels=x,\n",
        "                        yticklabels=y)\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Encoder Layer\", layer + 1)\n",
        "        for h in range(4):\n",
        "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
        "        plt.show()\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Decoder Self Layer\", layer+1)\n",
        "        for h in range(4):\n",
        "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Decoder Src Layer\", layer+1)\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        for h in range(4):\n",
        "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "8c69d3c2",
      "metadata": {
        "id": "8c69d3c2"
      },
      "outputs": [],
      "source": [
        "# ë²ˆì—­ ìƒì„± ë° Attention ì‹œê°í™” ê²°í•©\n",
        "\n",
        "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
        "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    if plot_attention:\n",
        "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "6d3dc349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791,
          "referenced_widgets": [
            "a64fefb56784415d8d239c08f08cff24",
            "92efff39bde945ab9afe34fdbbfbd3a4",
            "bfa97c3017e849d1b84180bc9902aaab",
            "bb2a394a599a4d36be18ca1fe6312a4f",
            "60788aaa6c814addbd209cd07f54be03",
            "f1ca046e033b48b898944d6e76a693a1",
            "45bdcb3cccb743aa914c6c83c652c0b3",
            "1cee12b7765446a18df588b206b15892",
            "3a98270559894096a3f18986345167d4",
            "d07f95396f3b498d9773dfeb81819493",
            "e1584818d67844058017788e1f70605e"
          ]
        },
        "id": "6d3dc349",
        "outputId": "3ada9879-f4f9-4653-edea-3c0728d477c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/34 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a64fefb56784415d8d239c08f08cff24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"<ipython-input-76-d70836a03263>\", line 8, in train_step  *\n        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"<ipython-input-144-43d15ff6954a>\", line 56, in call\n        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 217, in call\n        out, enc_attn = self.enc_layers[i](out, mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 128, in call\n        out = self.norm_1(x)\n\n    TypeError: Exception encountered when calling EncoderLayer.call().\n    \n    \u001b[1m'NoneType' object is not subscriptable\u001b[0m\n    \n    Arguments received by EncoderLayer.call():\n      â€¢ x=None\n      â€¢ mask=tf.Tensor(shape=(64, 1, 1, 22), dtype=float32)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-a9f91f57a657>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# í•™ìŠµ ë‹¨ê³„ ì‹¤í–‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# train_stepì—ì„œ ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ unpackingí•˜ë„ë¡ ì½”ë“œë¥¼ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         result = train_step(src=enc_train[idx:idx+BATCH_SIZE],\n\u001b[0m\u001b[1;32m     22\u001b[0m                             \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_file0qa92shs.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(src, tgt, model, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_enc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-144-43d15ff6954a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdec_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-2c1ad4714ddc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0menc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0menc_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-2c1ad4714ddc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[1;32m    127\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_self_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-76-d70836a03263>\", line 8, in train_step  *\n        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"<ipython-input-144-43d15ff6954a>\", line 56, in call\n        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 217, in call\n        out, enc_attn = self.enc_layers[i](out, mask)\n    File \"<ipython-input-132-2c1ad4714ddc>\", line 128, in call\n        out = self.norm_1(x)\n\n    TypeError: Exception encountered when calling EncoderLayer.call().\n    \n    \u001b[1m'NoneType' object is not subscriptable\u001b[0m\n    \n    Arguments received by EncoderLayer.call():\n      â€¢ x=None\n      â€¢ mask=tf.Tensor(shape=(64, 1, 1, 22), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5  # í•™ìŠµí•  Epoch ìˆ˜\n",
        "BATCH_SIZE = 64  # ë°°ì¹˜ í¬ê¸°\n",
        "\n",
        "example_sentences = [\n",
        "    \"ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\"\n",
        "    \"ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\"\n",
        "    \"ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\"\n",
        "    \"ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0.0  # total_lossë¥¼ ë¶€ë™ ì†Œìˆ˜ì ìœ¼ë¡œ ì´ˆê¸°í™”\n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)    # tqdm ì§„í–‰ ë°” ì‚¬ìš©\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        # í•™ìŠµ ë‹¨ê³„ ì‹¤í–‰\n",
        "        # train_stepì—ì„œ ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ unpackingí•˜ë„ë¡ ì½”ë“œë¥¼ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n",
        "        result = train_step(src=enc_train[idx:idx+BATCH_SIZE],\n",
        "                            tgt=dec_train[idx:idx+BATCH_SIZE],\n",
        "                            model=transformer,\n",
        "                            optimizer=optimizer)\n",
        "        if result is not None:\n",
        "            batch_loss, enc_attns, dec_attns, dec_enc_attns = result['loss'], result['enc_attns'], result['dec_attns'], result['dec_enc_attns']\n",
        "            total_loss += batch_loss.numpy() if hasattr(batch_loss, 'numpy') else batch_loss # batch_lossê°€ Tensorì¼ ê²½ìš° NumPy ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜\n",
        "        else:\n",
        "            print(f\"Warning: train_step returned None for batch {batch}, idx {idx}\")\n",
        "            # ì´ ê²½ìš° ì²˜ë¦¬ ë°©ì•ˆì„ ê³ ë ¤í•˜ì„¸ìš”. ì˜ˆ: ë°°ì¹˜ ê±´ë„ˆë›°ê¸° ë˜ëŠ” ì˜ˆì™¸ ë°œìƒ\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss / (batch + 1))) # total_lossê°€ ì´ì œ ë¶€ë™ ì†Œìˆ˜ì ì´ë¯€ë¡œ .numpy() ì œê±°\n",
        "\n",
        "    for example_sentence in tqdm(example_sentences): # example_sentencesë¥¼ example_sentenceë¡œ ë³€ê²½í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì˜ ê° ë¬¸ì¥ì„ ë°˜ë³µ\n",
        "        translate(example_sentence, transformer, ko_tokenizer, en_tokenizer, plot_attention=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0ffd0a",
      "metadata": {
        "id": "fc0ffd0a"
      },
      "source": [
        "**ê²°ë¡ :**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "912b023c63d14a44a74225ca50d5189f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9d71bbbd03342cdb536efa482d98bcb",
              "IPY_MODEL_5356b1fff7344b5691d8340249a93748",
              "IPY_MODEL_4670bef805c6415aa608ccc7b4e1fd44"
            ],
            "layout": "IPY_MODEL_824ee3fd77d545c6a26bd1bd4eab58d8"
          }
        },
        "b9d71bbbd03342cdb536efa482d98bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a24bdb32fa42c7876bd1acf998e212",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4677e172b82d430a84f11efce50f2285",
            "value": "100%"
          }
        },
        "5356b1fff7344b5691d8340249a93748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b98ee40f8d41f29a354758e32bad6d",
            "max": 78968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c23d51bf17c641aba9d03d7b66374186",
            "value": 78968
          }
        },
        "4670bef805c6415aa608ccc7b4e1fd44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97270071a3c6451aa511c927b319a6bd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_399c9d7fc11045d3b7dfae948de01122",
            "value": "â€‡78968/78968â€‡[00:00&lt;00:00,â€‡494216.11it/s]"
          }
        },
        "824ee3fd77d545c6a26bd1bd4eab58d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a24bdb32fa42c7876bd1acf998e212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4677e172b82d430a84f11efce50f2285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1b98ee40f8d41f29a354758e32bad6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23d51bf17c641aba9d03d7b66374186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97270071a3c6451aa511c927b319a6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399c9d7fc11045d3b7dfae948de01122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a64fefb56784415d8d239c08f08cff24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92efff39bde945ab9afe34fdbbfbd3a4",
              "IPY_MODEL_bfa97c3017e849d1b84180bc9902aaab",
              "IPY_MODEL_bb2a394a599a4d36be18ca1fe6312a4f"
            ],
            "layout": "IPY_MODEL_60788aaa6c814addbd209cd07f54be03"
          }
        },
        "92efff39bde945ab9afe34fdbbfbd3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ca046e033b48b898944d6e76a693a1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_45bdcb3cccb743aa914c6c83c652c0b3",
            "value": "â€‡â€‡0%"
          }
        },
        "bfa97c3017e849d1b84180bc9902aaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cee12b7765446a18df588b206b15892",
            "max": 34,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a98270559894096a3f18986345167d4",
            "value": 0
          }
        },
        "bb2a394a599a4d36be18ca1fe6312a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07f95396f3b498d9773dfeb81819493",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e1584818d67844058017788e1f70605e",
            "value": "â€‡0/34â€‡[00:00&lt;?,â€‡?it/s]"
          }
        },
        "60788aaa6c814addbd209cd07f54be03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ca046e033b48b898944d6e76a693a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45bdcb3cccb743aa914c6c83c652c0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cee12b7765446a18df588b206b15892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a98270559894096a3f18986345167d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d07f95396f3b498d9773dfeb81819493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1584818d67844058017788e1f70605e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}