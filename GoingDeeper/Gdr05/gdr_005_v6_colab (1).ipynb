{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7b33228d",
      "metadata": {
        "id": "7b33228d"
      },
      "source": [
        "### ì½”ë”ì˜ ì†ŒíšŒ :\n",
        "ë‚ ì”¨ : ì˜¤ëŠ˜ì˜ í•™ìŠµ < ë³´í†µâ˜ï¸>í–ˆìŠµë‹ˆë‹¤. [â˜€ï¸â›…â˜ï¸ğŸŒ§ï¸ğŸŒ©ï¸â›ˆï¸]\n",
        "- ë°°ìš´ì  : ì½”ë“œ ë‹¨ê³„ë³„ ìƒì„±í•˜ëŠ” ê²°ê³¼ë¬¼ì— ëŒ€í•œ ì´í•´ê°€ ë¶€ì¡±í•˜ë‹¤ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤.\n",
        "- ì•„ì‰¬ìš´ì  : ì—¬ëŸ¬ ì°¨ë¡€ ë‹¤ì–‘í•œ ì‹œë„ë¥¼ í–ˆì§€ë§Œ ì˜¤ë¥˜ê°€ ì˜¤ë¥˜ë¥¼ ë‚³ëŠ” ê²°ê³¼ë§Œ ì´ˆë˜í•˜ì—¬ ìµœì¢…ê²°ê³¼ë¬¼ì„ ëª»ë‚¸ ê²ƒ, ì „ë‚  18:00ë•Œì™€ í° ì°¨ì´ê°€ ì—†ëŠ” ê²ƒì´ ì•„ì‰½ìŠµë‹ˆë‹¤. \n",
        "- ëŠë‚€ì  :  ì–´ë””ë¶€í„° ê³µë¶€ë¥¼ ë‹¤ì‹œ í•´ì•¼í•˜ë‚˜ ìƒê°ì´ ë§ì•„ì¡ŒìŠµë‹ˆë‹¤. ìœµë‹˜ê»˜ì„œ ì•Œë ¤ì£¼ì‹  í¬ìŠ¤íŠ¸ì‡ ë°©ë²•ìœ¼ë¡œ ì•Œê³  ìˆëŠ” ë°”ë¥¼ ì •ë¦¬í•´ë³´ì•„ì•¼ê² ìŠµë‹ˆë‹¤. \n",
        "\n",
        "(ì°¸ê³  : https://github.com/Annyong2/AIFFEL_quest_rs/tree/master/GoingDeeper/Gdr05)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37ccd71b",
      "metadata": {
        "id": "37ccd71b"
      },
      "source": [
        "### ì „ì²´ ì½”ë“œ ì‹¤í–‰ í”Œë¡œìš° (ëª©ì°¨):\n",
        "\n",
        "**STEP 1. ë¶ˆëŸ¬ì˜¤ê¸° : ë¼ì´ë¸ŒëŸ¬ë¦¬ & ë°ì´í„°**  \n",
        "\n",
        "**STEP 2. ë°ì´í„° ì •ì œ ë° í† í°í™”**  \n",
        "\n",
        "**STEP 3. ëª¨ë¸ ì„¤ê³„**  \n",
        "\n",
        "**STEP 4. ëª¨ë¸ í›ˆë ¨**  \n",
        "\n",
        "**STEP 5. ë²ˆì—­ ë° ì‹œê°í™”**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b46bb90f",
      "metadata": {
        "id": "b46bb90f"
      },
      "source": [
        "**[TIP] STEP 4. ëª¨ë¸ ì„¤ê³„**\n",
        "- í•œêµ­ì–´ë¥¼ ì˜ì–´ë¡œ ì˜ ë²ˆì—­í•´ ì¤„ ë©‹ì§„ Attention ê¸°ë°˜ Seq2seq ëª¨ë¸ì„ ì„¤ê³„í•˜ì„¸ìš”!\n",
        "- ì•ì„œ ë§Œë“  ëª¨ë¸ì— Dropout ëª¨ë“ˆì„ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ ë” ì¢‹ì•„ì§‘ë‹ˆë‹¤!\n",
        "- Embedding Sizeì™€ Hidden SizeëŠ” ì‹¤í—˜ì„ í†µí•´ ì ë‹¹í•œ ê°’ì„ ë§ì¶° ì£¼ë„ë¡ í•©ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8d9fdc",
      "metadata": {
        "id": "8b8d9fdc"
      },
      "source": [
        "**[TIP] STEP 5. ëª¨ë¸ í›ˆë ¨**  \n",
        "- traing loss ì•ˆì •ì ìœ¼ë¡œ ë–¨ì–´ì§€ë©´ì„œ í•™ìŠµ ì§„í–‰  \n",
        "  \n",
        "**[TIP] STEP 6. ëª¨ë¸ í‰ê°€(í…ŒìŠ¤íŠ¸)**  \n",
        "- ë°ìŠ¤íŠ¸ìš© ë””ì½”ë” ëª¨ë¸ì˜ ì¶œë ¥ ê²°ê³¼ê°€ ì •ë‹µê³¼ ì–´ëŠ ì •ë„ ìœ ì‚¬í•œ ì˜ë²ˆì—­ ì§„í–‰"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31ae222",
      "metadata": {
        "id": "b31ae222"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55e1234d",
      "metadata": {
        "id": "55e1234d"
      },
      "source": [
        "# STEP 1. ë¶ˆëŸ¬ì˜¤ê¸° : ë¼ì´ë¸ŒëŸ¬ë¦¬ & ë°ì´í„°   \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5e35d20",
      "metadata": {
        "id": "c5e35d20"
      },
      "source": [
        "### 1.1 ë¼ì´ë¸ŒëŸ¬ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "aa696ce3",
      "metadata": {
        "id": "aa696ce3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import re\n",
        "import os\n",
        "import sentencepiece as spm\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm  # í°íŠ¸ ì„¤ì •\n",
        "\n",
        "\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "\n",
        "import seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "d3cb0079",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3cb0079",
        "outputId": "31084d2e-509e-48ab-a5db-552d4327ac58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "# í•œê¸€ì„¤ì •\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font = fm.FontProperties(fname=fontpath, size=9)\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "mpl.font_manager.findfont(font)\n",
        "\n",
        "print(\"ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7agOfILkfaL",
        "outputId": "87ac7ef0-f1aa-4ba3-9e39-016cbc794043"
      },
      "id": "Q7agOfILkfaL",
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "3baf27b3",
      "metadata": {
        "id": "3baf27b3"
      },
      "outputs": [],
      "source": [
        "# ë°ì´í„°ì…‹ ì €ì¥ê²½ë¡œ\n",
        "# data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
        "kor_path = '/content/drive/MyDrive/camp/korean-english-park.train.ko' # data_dir+\"/korean-english-park.train.ko\"\n",
        "eng_path = '/content/drive/MyDrive/camp/korean-english-park.train.en' # data_dir+\"/korean-english-park.train.en\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b739a233",
      "metadata": {
        "id": "b739a233"
      },
      "source": [
        "### ë°ì´í„° í™•ì¸"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9a34b7c",
      "metadata": {
        "id": "c9a34b7c"
      },
      "source": [
        "ë°ì´í„° ì¶œì²˜ : https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f5a10d",
      "metadata": {
        "id": "05f5a10d"
      },
      "source": [
        "#### 1.3 ë°ì´í„° í™•ì¸ : TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "7dac6ea9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dac6ea9",
        "outputId": "637540c8-2302-459d-881c-8e638ba88202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> ê°œì¸ìš© ì»´í“¨í„° ì‚¬ìš©ì˜ ìƒë‹¹ ë¶€ë¶„ì€ \"ì´ê²ƒë³´ë‹¤ ë›°ì–´ë‚  ìˆ˜ ìˆëŠëƒ?\"\n",
            ">> ë¶í•œì˜ í•µë¬´ê¸° ê³„íšì„ í¬ê¸°í•˜ë„ë¡ í•˜ë ¤ëŠ” ì••ë ¥ì´ ê±°ì„¸ì§€ê³  ìˆëŠ” ê°€ìš´ë°, ì¼ë³¸ê³¼ ë¶í•œì˜ ì™¸êµê´€ë“¤ì´ ì™¸êµ ê´€ê³„ë¥¼ ì •ìƒí™”í•˜ë ¤ëŠ” íšŒë‹´ì„ ì¬ê°œí–ˆë‹¤.\n",
            ">> \"ê²½í˜¸ ë¡œë³´íŠ¸ê°€ ì¹¨ì…ìë‚˜ í™”ì¬ë¥¼ íƒì§€í•˜ê¸° ìœ„í•´ì„œ ê°œì¸ì ìœ¼ë¡œ, ê·¸ë¦¬ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
            ">> ìˆ˜ìì›ë¶€ ë‹¹êµ­ì€ ë…¼ë€ì´ ë˜ê³  ìˆê³ , ë§‰ëŒ€í•œ ë¹„ìš©ì´ ë“œëŠ” ì´ ì‚¬ì—…ì— ëŒ€í•´ ë‚´ë…„ì— ê±´ì„¤ì„ ì‹œì‘í•  ê³„íšì´ë‹¤.\n",
            ">> ë˜í•œ ê·¼ë ¥ ìš´ë™ì€ í™œë°œí•˜ê²Œ ê±·ëŠ” ê²ƒì´ë‚˜ ìµœì†Œí•œ 20ë¶„ ë™ì•ˆ ë›°ëŠ” ê²ƒê³¼ ê°™ì€ ìœ ì‚°ì†Œ í™œë™ì—ì„œ ì–»ëŠ” ìš´ë™ íš¨ê³¼ë¥¼ ì‹¬ì¥ê³¼ íì— ì£¼ì§€ ì•Šê¸° ë•Œë¬¸ì—, ì—°êµ¬í•™ìë“¤ì€ ê·¼ë ¥ ìš´ë™ì´ ì‹¬ì¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì—¬ë¶€ì— ëŒ€í•´ ë…¼ìŸì„ í•´ì™”ë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# KOREAN\n",
        "# ë°ì´í„° í˜•íƒœ í™•ì¸\n",
        "with open(kor_path, \"r\") as f:\n",
        "    raw_ko = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_ko))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen_ko in raw_ko[0:100][::20]: print(\">>\", sen_ko)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "09ba9ac4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ba9ac4",
        "outputId": "b3c49ba1-d1eb-401e-9093-cf48637d57f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> Much of personal computing is about \"can you top this?\"\n",
            ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
            ">> â€œGuard robots are used privately and professionally to detect intruders or fire,â€ Karlsson said.\n",
            ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
            ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
          ]
        }
      ],
      "source": [
        "# ENGLISH\n",
        "# ë°ì´í„° í˜•íƒœ í™•ì¸\n",
        "with open(eng_path, \"r\") as f:\n",
        "    raw_en = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw_en))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen_en in raw_en[0:100][::20]: print(\">>\", sen_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "499d98d8",
      "metadata": {
        "id": "499d98d8"
      },
      "source": [
        "##### ì½”ë©˜íŠ¸:\n",
        "í•œêµ­ì–´ë°ì´í„°ì™€ ì˜ì–´ë°ì´í„° í¬ê¸°ê°€ ë™ì¼í•˜ë‹¤.    \n",
        "ë‘ íŒŒì¼ë¡œ ë‚˜ëˆ ì ¸ìˆëŠ” ë°ì´í„°ë“¤ì€ ìˆœì„œ(idx)ë„ ë§¤í•‘ë˜ì–´ìˆë‹¤.(raw_ko[1] = raw_en[1])      \n",
        "=> ë³‘ë ¬ë¡œ ë¬¶ëŠ”ë‹¤"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d042d192",
      "metadata": {
        "id": "d042d192"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7204b527",
      "metadata": {
        "id": "7204b527"
      },
      "source": [
        "# Step 2. ë°ì´í„° ì •ì œ ë° í† í°í™”   \n",
        "\n",
        "2.1 ë°ì´í„° ì •ì œ  \n",
        "2.2 ë°ì´í„° í† í°í™”  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd08979c",
      "metadata": {
        "id": "bd08979c"
      },
      "source": [
        "### 2.1.1 ë°ì´í„° ì •ì œ : ë³‘ë ¬ ë°ì´í„°ì…‹ ìƒì„± ë° ì¤‘ë³µì œê±°(set()ì‚¬ìš©)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "4749410f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4749410f",
        "outputId": "7412e1d7-07c4-4ae1-fb4e-e32ea2bf0836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë³‘ë ¬ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ\n",
            "ë³‘ë ¬ ë°ì´í„°ì…‹ ì¤‘ë³µì œê±° ì™„ë£Œ : 94123 ->78968 \n",
            "\n",
            "Type(cleaned_corpus) :  <class 'list'> \n",
            " [('ê°¤ëŸ½ ì—¬ë¡ ì¡°ì‚¬ëŠ” 1930ë…„ëŒ€ë¶€í„° ì‹¤ì‹œëì§€ë§Œ ëŒ€í†µë ¹ì— ëŒ€í•œ ì§€ì§€ìœ¨ì„ ì›”ë³„ë¡œ ë°œí‘œí•œ ê²ƒì€ íŠ¸ë£¨ë¨¼ ì‹œëŒ€ë¶€í„°ë‹¤.', \"While Gallup polling goes back to the 1930s, it wasn't until the Truman years that they began surveying monthly approval ratings.\")]\n"
          ]
        }
      ],
      "source": [
        "def clean_corpus(kor_path, eng_path):\n",
        "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
        "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
        "    assert len(kor) == len(eng)\n",
        "\n",
        "    dataset = list(zip(kor, eng))\n",
        "    print(\"ë³‘ë ¬ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ\")\n",
        "    cleaned_corpus = list(set(dataset))\n",
        "    print(f\"ë³‘ë ¬ ë°ì´í„°ì…‹ ì¤‘ë³µì œê±° ì™„ë£Œ : {len(dataset)} ->{len(cleaned_corpus)}\",\"\\n\")\n",
        "    ko_corpus, en_corpus = zip(*cleaned_corpus)\n",
        "\n",
        "    return cleaned_corpus, ko_corpus, en_corpus\n",
        "\n",
        "\n",
        "cleaned_corpus, ko_corpus, en_corpus = clean_corpus(kor_path, eng_path)\n",
        "\n",
        "print(\"Type(cleaned_corpus) : \", type(cleaned_corpus),\"\\n\",cleaned_corpus[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dcffccd",
      "metadata": {
        "id": "6dcffccd"
      },
      "source": [
        "##### ì¤‘ë³µì œê±° í›„ ì½”ë©˜íŠ¸ :\n",
        "\n",
        "\n",
        "ì˜í•œ ë°ì´í„°ë¥¼ ë³‘ë ¬êµ¬ì¡°ë¡œ ë§Œë“¤ê³ , set()ë§¤ì¨ë“œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µì œê±°ë¥¼ í•˜ì˜€ë‹¤.  \n",
        "\n",
        "ë°ì´í„° ì¤‘ë³µ ì œê±°í›„, ë°ì´í„°ëŠ” ì´ì „ì˜ 80%(94123 ->78968)ì •ë„ ë‚¨ì•˜ë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd54780d",
      "metadata": {
        "id": "dd54780d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73570d0",
      "metadata": {
        "id": "e73570d0"
      },
      "source": [
        "### 2.1.2 ë°ì´í„° ì •ì œ : ë°ì´í„° ì „ì²˜ë¦¬ (lms 4ê°€ì§€ ë°˜ì˜ ì™„ë£Œ)\n",
        "- ëª¨ë“  ì…ë ¥ì„ ì†Œë¬¸ìë¡œ ë³€í™˜\n",
        "- ì•ŒíŒŒë²³, ë¬¸ì¥ë¶€í˜¸, í•œê¸€ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°\n",
        "- ë¬¸ì¥ë¶€í˜¸ ì–‘ì˜†ì— ê³µë°±ì„ ì¶”ê°€\n",
        "- ë¬¸ì¥ ì•ë’¤ì˜ ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì œê±°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e561e4f",
      "metadata": {
        "id": "2e561e4f"
      },
      "source": [
        "##### ì „ì²˜ë¦¬ í•¨ìˆ˜ preprocess_sentence ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "7b3a11bd",
      "metadata": {
        "id": "7b3a11bd"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    # 1. ì†Œë¬¸ì ë³€í™˜\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    # 2. ì•ŒíŒŒë²³, ë¬¸ì¥ë¶€í˜¸, í•œê¸€ ì™¸ ì œê±°\n",
        "    sentence = re.sub(r'\\d', '', sentence)\n",
        "\n",
        "    # 3. ë¬¸ì¥ë¶€í˜¸ ì–‘ì˜† ê³µë°± ì¶”ê°€\n",
        "    sentence = re.sub(r'(\\W)', r' \\1 ', sentence)\n",
        "\n",
        "    # 4. ë¬¸ì¥ ì•ë’¤ ê³µë°± ì œê±°\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    # 5. ì¤‘ë³µëœ ê³µë°± ì œê±°(NoneType object)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7d0ebef",
      "metadata": {
        "id": "b7d0ebef"
      },
      "source": [
        "##### ì „ì²˜ë¦¬ í•¨ìˆ˜ preprocess_sentenceì‘ë™ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "6f80e0dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f80e0dc",
        "outputId": "659c767b-278c-4b8c-ce59-d89aeeea4c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¯¸í•˜ì¼ ì¹´ë¯¸ë‹Œ ëŸ¬ì‹œì•„ ì™¸ë¬´ë¶€ ëŒ€ë³€ì¸ì€ ê¸°ìíšŒê²¬ì—ì„œ â€œëŸ¬ì‹œì•„ê°€ 19ì¼ 4ëª…ì˜ ì˜êµ­ ì™¸êµê´€ì„ ì¶”ë°©í•œ ê²ƒì€ ì˜êµ­ ì •ë¶€ê°€ ì·¨í•œ ì¡°ì¹˜ì— ëŒ€í•œ ë°˜ì‘ì´ë‹¤â€ë¼ê³  ë°œí‘œí–ˆë‹¤.\n",
            "ë¯¸í•˜ì¼ ì¹´ë¯¸ë‹Œ ëŸ¬ì‹œì•„ ì™¸ë¬´ë¶€ ëŒ€ë³€ì¸ì€ ê¸°ìíšŒê²¬ì—ì„œ â€œ ëŸ¬ì‹œì•„ê°€ ì¼ ëª…ì˜ ì˜êµ­ ì™¸êµê´€ì„ ì¶”ë°©í•œ ê²ƒì€ ì˜êµ­ ì •ë¶€ê°€ ì·¨í•œ ì¡°ì¹˜ì— ëŒ€í•œ ë°˜ì‘ì´ë‹¤ â€ ë¼ê³  ë°œí‘œí–ˆë‹¤ .\n"
          ]
        }
      ],
      "source": [
        "# í™•ì¸\n",
        "text = 'ë¯¸í•˜ì¼ ì¹´ë¯¸ë‹Œ ëŸ¬ì‹œì•„ ì™¸ë¬´ë¶€ ëŒ€ë³€ì¸ì€ ê¸°ìíšŒê²¬ì—ì„œ â€œëŸ¬ì‹œì•„ê°€ 19ì¼ 4ëª…ì˜ ì˜êµ­ ì™¸êµê´€ì„ ì¶”ë°©í•œ ê²ƒì€ ì˜êµ­ ì •ë¶€ê°€ ì·¨í•œ ì¡°ì¹˜ì— ëŒ€í•œ ë°˜ì‘ì´ë‹¤â€ë¼ê³  ë°œí‘œí–ˆë‹¤.'\n",
        "print(text)\n",
        "print(preprocess_sentence(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd9edba",
      "metadata": {
        "id": "4dd9edba"
      },
      "source": [
        "### 2.2.1 ë°ì´í„° í† í°í™”"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df18ea04",
      "metadata": {
        "id": "df18ea04"
      },
      "source": [
        "##### í† í°í™” í•¨ìˆ˜ generate_tokenizer ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "a2008ec5",
      "metadata": {
        "id": "a2008ec5"
      },
      "outputs": [],
      "source": [
        "# Sentencepieceë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµí•œ tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "# ì½”í¼ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  SentencePieceì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •\n",
        "def save_corpus(corpus, filepath):\n",
        "    with open(filepath, 'w') as f:\n",
        "        for line in corpus:\n",
        "            f.write(f\"{line}\\n\")\n",
        "\n",
        "# SentencePieceì—ì„œ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "def generate_tokenizer(corpus,\n",
        "                       vocab_size,\n",
        "                       lang=\"ko\",\n",
        "                       pad_id=0,\n",
        "                       bos_id=1,\n",
        "                       eos_id=2,\n",
        "                       unk_id=3):\n",
        "    corpus_file = f\"{lang}_corpus.txt\"\n",
        "    save_corpus(corpus, corpus_file)\n",
        "\n",
        "    # SentencePiece í•™ìŠµ ì‹œ ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜ ì¶”ê°€\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=corpus_file,\n",
        "        model_prefix=f\"{lang}_tokenizer\",\n",
        "        vocab_size=vocab_size,\n",
        "        pad_id=pad_id,\n",
        "        bos_id=bos_id,\n",
        "        eos_id=eos_id,\n",
        "        unk_id=unk_id,\n",
        "        num_threads=4  # ë³‘ë ¬ ì²˜ë¦¬ ì˜µì…˜ ì¶”ê°€\n",
        "    )\n",
        "\n",
        "    # í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    tokenizer = spm.SentencePieceProcessor()\n",
        "    tokenizer.Load(f\"{lang}_tokenizer.model\")\n",
        "\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b78430",
      "metadata": {
        "id": "24b78430"
      },
      "source": [
        "##### ì „ì²˜ë¦¬í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "21acc024",
      "metadata": {
        "id": "21acc024"
      },
      "outputs": [],
      "source": [
        "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
        "\n",
        "N = len(cleaned_corpus)\n",
        "kor_corpus = []\n",
        "eng_corpus = []\n",
        "for i in range(N):\n",
        "    kor_corpus.append(preprocess_sentence(ko_corpus[i]))\n",
        "    eng_corpus.append(preprocess_sentence(en_corpus[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "ca68bf79",
      "metadata": {
        "id": "ca68bf79"
      },
      "outputs": [],
      "source": [
        "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "85fc8a6f",
      "metadata": {
        "id": "85fc8a6f"
      },
      "outputs": [],
      "source": [
        "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "952cfb8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "952cfb8f",
        "outputId": "78f093eb-b2af-496d-f4a4-fd4f17b4262b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "79094d7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "425576cf3cea45229ba9e424ae81cdea",
            "eb9396c0c746405ab81f429dafd66b34",
            "6e7f34e8bea24904acc80a7f8396a668",
            "93c7e6bdf31c4f28aae517577e541aec",
            "665958e408cb40f3b915e8da7623aae5",
            "e53156c5a66440dfbbda02469e91fe51",
            "3d7a2073153448308d0a267a809767d7",
            "cad1a2d61b024c8eb097574138731acc",
            "9abdd0b500264860ad0c1086e1f097a9",
            "dd6e8bdeb610438a9736dc7772d54ce9",
            "0e712c750d85484bbf87b13033c89e7a"
          ]
        },
        "id": "79094d7c",
        "outputId": "a0bc35bc-632c-4a37-d7db-89c84c30e0fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/78968 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "425576cf3cea45229ba9e424ae81cdea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4794\n",
            "4794\n"
          ]
        }
      ],
      "source": [
        "src_corpus = []\n",
        "tgt_corpus = []\n",
        "\n",
        "assert len(kor_corpus) == len(eng_corpus)\n",
        "\n",
        "# í† í°ì˜ ê¸¸ì´ê°€ 50 ì´í•˜ì¸ ë¬¸ì¥ë§Œ ë‚¨ê¹ë‹ˆë‹¤.\n",
        "for idx in tqdm(range(len(kor_corpus))):\n",
        "    if len(kor_corpus[idx]) <= 50 and len(eng_corpus[idx]) <= 50:  # len(kor_corpus[idx]) <= 50:\n",
        "        src_corpus.append(kor_corpus[idx])\n",
        "        tgt_corpus.append(eng_corpus[idx])\n",
        "    else :\n",
        "        pass\n",
        "\n",
        "print(len(src_corpus))\n",
        "print(len(tgt_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "d6af689b",
      "metadata": {
        "id": "d6af689b"
      },
      "outputs": [],
      "source": [
        "# ko_tokenizerì™€ en_tokenizerë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\n",
        "src_corpus_tokenized = [ko_tokenizer.encode_as_ids(sentence) for sentence in src_corpus]\n",
        "tgt_corpus_tokenized = [en_tokenizer.encode_as_ids(sentence) for sentence in tgt_corpus]\n",
        "\n",
        "# íŒ¨ë”©ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ì—¬ í•™ìŠµìš© ë°ì´í„°ë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.\n",
        "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus_tokenized, padding='post')\n",
        "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus_tokenized, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e73d16e",
      "metadata": {
        "id": "7e73d16e"
      },
      "source": [
        "ğŸ‘ï¸ğŸ‘ï¸**ì½”ë©˜íŠ¸ :**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ad4125",
      "metadata": {
        "id": "40ad4125"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e5f7ec1",
      "metadata": {
        "id": "7e5f7ec1"
      },
      "source": [
        "# STEP 3. ëª¨ë¸ ì„¤ê³„  \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PositionalEncoding\n",
        "## ìš©ë„ : ì…ë ¥ ìœ„ì¹˜ì— ë”°ë¼ ìœ„ì¹˜ ì¸ì½”ë”© ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "def positional_encoding(pos, d_model):\n",
        "    def cal_angle(position, i):\n",
        "        return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "    return sinusoid_table\n",
        "\n",
        "print(\"class positional_encoding, return sinusoid_table\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAq-Lq023yg9",
        "outputId": "c98df6b0-84ce-46bf-ff09-e545c1181b8a"
      },
      "id": "CAq-Lq023yg9",
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class positional_encoding, return sinusoid_table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MultiHeadAttention\n",
        "## ìš©ë„ : ì…ë ¥ì— ëŒ€í•œ ì—¬ëŸ¬ í—¤ë“œì˜ ì–´í…ì…˜ì„ ê³„ì‚°í•˜ì—¬ ê²°í•©í•©ë‹ˆë‹¤.\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.W_q = tf.keras.layers.Dense(d_model)\n",
        "        self.W_k = tf.keras.layers.Dense(d_model)\n",
        "        self.W_v = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.linear = tf.keras.layers.Dense(d_model)\n",
        "    '''\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "        QK = tf.matmul(Q, K, transpose_b=True)\n",
        "\n",
        "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None: scaled_qk += (mask * -1e9)\n",
        "\n",
        "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "        out = tf.matmul(attentions, V)\n",
        "\n",
        "        return out, attentions\n",
        "    '''\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "        QK = tf.matmul(Q, K, transpose_b=True)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "        # QK ì°¨ì›ì— ë§ê²Œ ë§ˆìŠ¤í¬ì˜ ë§ˆì§€ë§‰ ì°¨ì›ì„ seq_len_kë¡œ í™•ì¥\n",
        "        if mask is not None:\n",
        "            mask = tf.expand_dims(mask, axis=2)  # (batch_size, num_heads, 1, seq_len_k)\n",
        "            scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "            scaled_qk += (mask * -1e9)  # broadcastingìœ¼ë¡œ ì ìš©\n",
        "        else:\n",
        "            scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "        out = tf.matmul(attentions, V)\n",
        "\n",
        "        return out, attentions\n",
        "\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        split_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "        return split_x\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
        "\n",
        "        return combined_x\n",
        "\n",
        "\n",
        "    def call(self, Q, K, V, mask):\n",
        "        WQ = self.W_q(Q)\n",
        "        WK = self.W_k(K)\n",
        "        WV = self.W_v(V)\n",
        "\n",
        "        WQ_splits = self.split_heads(WQ)\n",
        "        WK_splits = self.split_heads(WK)\n",
        "        WV_splits = self.split_heads(WV)\n",
        "\n",
        "        out, attention_weights = self.scaled_dot_product_attention(\n",
        "            WQ_splits, WK_splits, WV_splits, mask)\n",
        "\n",
        "        out = self.combine_heads(out)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out, attention_weights\n",
        "\n",
        "print(\"class MultiHeadAttention\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVtB0Auo31R3",
        "outputId": "9749a77f-cd39-4852-a54b-42554bebaa7b"
      },
      "id": "mVtB0Auo31R3",
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class MultiHeadAttention\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.w_1(x)\n",
        "        out = self.w_2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"class PoswiseFeedForwardNet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9wgSxRs38Oi",
        "outputId": "98760087-da03-4e51-c1f9-4b1a6cde15ea"
      },
      "id": "d9wgSxRs38Oi",
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class PoswiseFeedForwardNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "id": "f46fd2f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46fd2f8",
        "outputId": "b5d5f220-d929-40fc-fe3f-92d8b4b78d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class EncoderLayer, return out, enc_attn\n",
            "class DecoderLayer, return out, dec_attn, dec_enc_attn\n",
            "class Encoder, return out, enc_attns\n",
            "class Decoder, return out, dec_attns, dec_enc_attns\n"
          ]
        }
      ],
      "source": [
        "## EncoderLayer\n",
        "## ìš©ë„ : ì…ë ¥ì„ ì¸ì½”ë”ì— ì „ë‹¬í•˜ì—¬ ì–´í…ì…˜ ë° í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, enc_attn\n",
        "\n",
        "print(\"class EncoderLayer, return out, enc_attn\")\n",
        "\n",
        "## DecoderLayer\n",
        "## ìš©ë„ : ì…ë ¥ì„ ë””ì½”ë”ì— ì „ë‹¬í•˜ì—¬ ì–´í…ì…˜ ë° í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Masked Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, dec_attn = self.dec_self_attn(out, out, out, causality_mask) # padding_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, padding_mask) # causality_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_3(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, dec_attn, dec_enc_attn\n",
        "print(\"class DecoderLayer, return out, dec_attn, dec_enc_attn\")\n",
        "\n",
        "## Encoder\n",
        "## ìš©ë„ : ì—¬ëŸ¬ ê°œì˜ ì¸ì½”ë” ë ˆì´ì–´ë¥¼ ìŒ“ì•„ ì „ì²´ ì¸ì½”ë”ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                        for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        out = x\n",
        "\n",
        "        enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, enc_attn = self.enc_layers[i](out, mask)\n",
        "            enc_attns.append(enc_attn)\n",
        "\n",
        "        return out, enc_attns\n",
        "\n",
        "print(\"class Encoder, return out, enc_attns\")\n",
        "\n",
        "## Decoder\n",
        "## ìš©ë„ : ì—¬ëŸ¬ ê°œì˜ ë””ì½”ë” ë ˆì´ì–´ë¥¼ ìŒ“ì•„ ì „ì²´ ë””ì½”ë”ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                            for _ in range(n_layers)]\n",
        "\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        out = x\n",
        "\n",
        "        dec_attns = list()\n",
        "        dec_enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, dec_attn, dec_enc_attn = \\\n",
        "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "            dec_attns.append(dec_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "        return out, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"class Decoder, return out, dec_attns, dec_enc_attns\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer\n",
        "## ìš©ë„ : ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ê²°í•©í•˜ì—¬ ì „ì²´ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 src_vocab_size,\n",
        "                 tgt_vocab_size,\n",
        "                 pos_len,\n",
        "                 dropout=0.2,\n",
        "                 shared=False):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.shared = shared\n",
        "\n",
        "        # 1. Embedding Layer ì •ì˜\n",
        "        self.src_embedding = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # 2. Positional Encoding ì •ì˜\n",
        "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
        "        # 6. Dropout ì •ì˜\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        # 3. Encoder / Decoder ì •ì˜\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        # 4. Output Linear ì •ì˜\n",
        "        self.out_linear = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "        self.shared = shared\n",
        "\n",
        "        # 5. Shared Weights\n",
        "        if shared: self.out_linear.set_weights(tf.transpose(self.tgt_embedding.weights))\n",
        "\n",
        "\n",
        "    def embedding(self, emb, x):\n",
        "        seq_len = x.shape[1]\n",
        "        out = emb(x)\n",
        "\n",
        "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "        \"\"\"\n",
        "        ìˆœì„œì— ë”°ë¼ Encoder, Decoder, ê·¸ë¦¬ê³  Output ê³„ì‚°\n",
        "        \"\"\"\n",
        "        enc_in = self.embedding(self.src_embedding, enc_in)\n",
        "        dec_in = self.embedding(self.tgt_embedding, dec_in)\n",
        "\n",
        "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "\n",
        "        dec_out, dec_attns, dec_enc_attns = \\\n",
        "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "\n",
        "        # Step 4: Out Linear(dec_out)\n",
        "        logits = self.out_linear(dec_out)\n",
        "\n",
        "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"Transformer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqYMyJNEyWyZ",
        "outputId": "de76f889-ca10-489d-8486-93004f713b18"
      },
      "id": "GqYMyJNEyWyZ",
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64884fe0",
      "metadata": {
        "id": "64884fe0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803d6c43",
      "metadata": {
        "id": "803d6c43"
      },
      "source": [
        "# STEP 4. ëª¨ë¸ í›ˆë ¨\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "id": "c7b5e084",
      "metadata": {
        "id": "c7b5e084"
      },
      "outputs": [],
      "source": [
        "def generate_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "'''\n",
        "def generate_causality_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "'''\n",
        "# generate_causality_mask í•¨ìˆ˜ ìˆ˜ì •\n",
        "def generate_causality_mask(tgt):\n",
        "    size = tf.shape(tgt)[1]  # ì‹œí€€ìŠ¤ ê¸¸ì´ ì¶”ì¶œ\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def generate_masks(src, tgt):\n",
        "    enc_mask = generate_padding_mask(src)\n",
        "    dec_mask = generate_causality_mask(tgt)\n",
        "    dec_enc_mask = generate_padding_mask(tgt)\n",
        "\n",
        "    # ì†ŒìŠ¤ ì‹œí€€ìŠ¤ì™€ íƒ€ê²Ÿ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ë¥¼ ë§ì¶”ëŠ” ë°©ì‹ ì ìš©\n",
        "    # tf.maximumì„ ì‚¬ìš©í•˜ì—¬ íŒ¨ë”© ê°’ì´ ìŒìˆ˜ê°€ ë˜ëŠ” ê²ƒì„ ë°©ì§€\n",
        "    if tf.shape(src)[1] != tf.shape(tgt)[1]:\n",
        "        padding_value = tf.maximum(0, tf.shape(src)[1] - tf.shape(tgt)[1])\n",
        "        dec_enc_mask = tf.pad(dec_enc_mask, [[0, 0], [0, 0], [0, 0], [0, padding_value]])\n",
        "\n",
        "    return enc_mask, dec_enc_mask, dec_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "id": "300ce39c",
      "metadata": {
        "id": "300ce39c"
      },
      "outputs": [],
      "source": [
        "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(LearningRateScheduler, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = step ** -0.5\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "id": "4ba81c9d",
      "metadata": {
        "scrolled": true,
        "id": "4ba81c9d"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(n_layers=2,\n",
        "                          d_model=512,\n",
        "                          n_heads=8,\n",
        "                          d_ff=2048,\n",
        "                          src_vocab_size=SRC_VOCAB_SIZE,\n",
        "                          tgt_vocab_size=TGT_VOCAB_SIZE,\n",
        "                          pos_len=50,\n",
        "                          shared=True\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "id": "2116b111",
      "metadata": {
        "id": "2116b111"
      },
      "outputs": [],
      "source": [
        "learning_rate = LearningRateScheduler(512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "id": "e603b998",
      "metadata": {
        "id": "e603b998"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    # Masking ë˜ì§€ ì•Šì€ ì…ë ¥ì˜ ê°œìˆ˜ë¡œ Scalingí•˜ëŠ” ê³¼ì •\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "id": "cc5e934f",
      "metadata": {
        "id": "cc5e934f"
      },
      "outputs": [],
      "source": [
        "@tf.function()\n",
        "def train_step(src, tgt, model, optimizer):\n",
        "    # ì…ë ¥ í…ì„œì˜ ì°¨ì›ì„ ë””ë²„ê¹…\n",
        "    print(f\"Source input shape: {src.shape}, Target input shape: {tgt.shape}\")\n",
        "\n",
        "    gold = tgt[:, 1:]\n",
        "    loss = 0\n",
        "\n",
        "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
        "\n",
        "    # ê³„ì‚°ëœ lossì— tf.GradientTape()ë¥¼ ì ìš©í•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
        "        loss = loss_function(gold, predictions[:, :-1])\n",
        "\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, enc_attns, dec_attns, dec_enc_attns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2f749c",
      "metadata": {
        "id": "de2f749c"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7affabb",
      "metadata": {
        "id": "e7affabb"
      },
      "source": [
        "# STEP 5. ë²ˆì—­ ë° ì‹œê°í™”  \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "id": "ab4d7fb4",
      "metadata": {
        "id": "ab4d7fb4"
      },
      "outputs": [],
      "source": [
        "# ë²ˆì—­ ìƒì„± í•¨ìˆ˜\n",
        "\n",
        "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
        "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
        "\n",
        "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    ids = []\n",
        "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
        "    for i in range(dec_train.shape[-1]):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
        "        generate_masks(_input, output)\n",
        "\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
        "        model(_input,\n",
        "              output,\n",
        "              enc_padding_mask,\n",
        "              combined_mask,\n",
        "              dec_padding_mask)\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
        "\n",
        "        if tgt_tokenizer.eos_id() == predicted_id:\n",
        "            result = tgt_tokenizer.decode_ids(ids)\n",
        "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "        ids.append(predicted_id)\n",
        "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
        "\n",
        "    result = tgt_tokenizer.decode_ids(ids)\n",
        "\n",
        "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "id": "bf99240a",
      "metadata": {
        "id": "bf99240a"
      },
      "outputs": [],
      "source": [
        "# Attention ì‹œê°í™” í•¨ìˆ˜\n",
        "\n",
        "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
        "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
        "        import seaborn\n",
        "        seaborn.heatmap(data,\n",
        "                        square=True,\n",
        "                        vmin=0.0, vmax=1.0,\n",
        "                        cbar=False, ax=ax,\n",
        "                        xticklabels=x,\n",
        "                        yticklabels=y)\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Encoder Layer\", layer + 1)\n",
        "        for h in range(4):\n",
        "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
        "        plt.show()\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Decoder Self Layer\", layer+1)\n",
        "        for h in range(4):\n",
        "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Decoder Src Layer\", layer+1)\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        for h in range(4):\n",
        "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "id": "8c69d3c2",
      "metadata": {
        "id": "8c69d3c2"
      },
      "outputs": [],
      "source": [
        "# ë²ˆì—­ ìƒì„± ë° Attention ì‹œê°í™” ê²°í•©\n",
        "\n",
        "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
        "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    if plot_attention:\n",
        "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "id": "6d3dc349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253,
          "referenced_widgets": [
            "b457b989939d482b9b767bb5633cb86e",
            "a6ef2de4cd0a49cf80d1aca109aed263",
            "c87caebcb0854dd9b7203dbaeb00f9c2",
            "05deab3c24e8469c95888feabbbfa981",
            "c2918207c0e940ff8a4ddd6985711dfc",
            "60f38360feb440eab7d67dbcf639fd89",
            "c64501f22de84b78a745f7a0467acdda",
            "1e222441ca934d9d8151e5f1596adc68",
            "361fdd45a36f46d49f8cbb9bb77d30b2",
            "e40281ad4b6249939ac0daa1eb57190f",
            "08532770276e445cb2a7a591907166ff"
          ]
        },
        "id": "6d3dc349",
        "outputId": "5d9c0672-19f4-4a13-d08c-12ed12f8c561"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/75 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b457b989939d482b9b767bb5633cb86e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable NoneType object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-302-3225e14dd787>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         train_step(enc_train[idx:idx+BATCH_SIZE],\n\u001b[1;32m     24\u001b[0m                     \u001b[0mdec_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5  # í•™ìŠµí•  Epoch ìˆ˜\n",
        "BATCH_SIZE = 64  # ë°°ì¹˜ í¬ê¸°\n",
        "\n",
        "\n",
        "model_list =[]\n",
        "\n",
        "examples = [\n",
        "            \"ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\",\n",
        "            \"ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\",\n",
        "            \"ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\",\n",
        "            \"ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                    dec_train[idx:idx+BATCH_SIZE],\n",
        "                    transformer,\n",
        "                    optimizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "\n",
        "    for example in tqdm(examples):\n",
        "        translate(example, transformer, ko_tokenizer, en_tokenizer)\n",
        "\n",
        "    model_list.append(transformer.get_weights())\n",
        "\n",
        "'''\n",
        "example_sentences = [\n",
        "    \"ì˜¤ë°”ë§ˆëŠ” ëŒ€í†µë ¹ì´ë‹¤.\"\n",
        "    \"ì‹œë¯¼ë“¤ì€ ë„ì‹œ ì†ì— ì‚°ë‹¤.\"\n",
        "    \"ì»¤í”¼ëŠ” í•„ìš” ì—†ë‹¤.\"\n",
        "    \"ì¼ê³± ëª…ì˜ ì‚¬ë§ìê°€ ë°œìƒí–ˆë‹¤.\"\n",
        "]\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0.0  # total_lossë¥¼ ë¶€ë™ ì†Œìˆ˜ì ìœ¼ë¡œ ì´ˆê¸°í™”\n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm(idx_list)    # tqdm ì§„í–‰ ë°” ì‚¬ìš©\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        # í•™ìŠµ ë‹¨ê³„ ì‹¤í–‰\n",
        "        # train_stepì—ì„œ ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ unpackingí•˜ë„ë¡ ì½”ë“œë¥¼ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\n",
        "        result = train_step(src=enc_train[idx:idx+BATCH_SIZE],\n",
        "                            tgt=dec_train[idx:idx+BATCH_SIZE],\n",
        "                            model=transformer,\n",
        "                            optimizer=optimizer)\n",
        "        if result is not None:\n",
        "            batch_loss, enc_attns, dec_attns, dec_enc_attns = result['loss'], result['enc_attns'], result['dec_attns'], result['dec_enc_attns']\n",
        "            total_loss += batch_loss.numpy() if hasattr(batch_loss, 'numpy') else batch_loss # batch_lossê°€ Tensorì¼ ê²½ìš° NumPy ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜\n",
        "        else:\n",
        "            print(f\"Warning: train_step returned None for batch {batch}, idx {idx}\")\n",
        "            # ì´ ê²½ìš° ì²˜ë¦¬ ë°©ì•ˆì„ ê³ ë ¤í•˜ì„¸ìš”. ì˜ˆ: ë°°ì¹˜ ê±´ë„ˆë›°ê¸° ë˜ëŠ” ì˜ˆì™¸ ë°œìƒ\n",
        "\n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss / (batch + 1))) # total_lossê°€ ì´ì œ ë¶€ë™ ì†Œìˆ˜ì ì´ë¯€ë¡œ .numpy() ì œê±°\n",
        "\n",
        "    for example_sentence in tqdm(example_sentences): # example_sentencesë¥¼ example_sentenceë¡œ ë³€ê²½í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì˜ ê° ë¬¸ì¥ì„ ë°˜ë³µ\n",
        "        translate(example_sentence, transformer, ko_tokenizer, en_tokenizer, plot_attention=True)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0ffd0a",
      "metadata": {
        "id": "fc0ffd0a"
      },
      "source": [
        "**ê²°ë¡ :**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "425576cf3cea45229ba9e424ae81cdea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb9396c0c746405ab81f429dafd66b34",
              "IPY_MODEL_6e7f34e8bea24904acc80a7f8396a668",
              "IPY_MODEL_93c7e6bdf31c4f28aae517577e541aec"
            ],
            "layout": "IPY_MODEL_665958e408cb40f3b915e8da7623aae5"
          }
        },
        "eb9396c0c746405ab81f429dafd66b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53156c5a66440dfbbda02469e91fe51",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3d7a2073153448308d0a267a809767d7",
            "value": "100%"
          }
        },
        "6e7f34e8bea24904acc80a7f8396a668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cad1a2d61b024c8eb097574138731acc",
            "max": 78968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9abdd0b500264860ad0c1086e1f097a9",
            "value": 78968
          }
        },
        "93c7e6bdf31c4f28aae517577e541aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd6e8bdeb610438a9736dc7772d54ce9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0e712c750d85484bbf87b13033c89e7a",
            "value": "â€‡78968/78968â€‡[00:00&lt;00:00,â€‡457630.24it/s]"
          }
        },
        "665958e408cb40f3b915e8da7623aae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53156c5a66440dfbbda02469e91fe51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d7a2073153448308d0a267a809767d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cad1a2d61b024c8eb097574138731acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9abdd0b500264860ad0c1086e1f097a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd6e8bdeb610438a9736dc7772d54ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e712c750d85484bbf87b13033c89e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b457b989939d482b9b767bb5633cb86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6ef2de4cd0a49cf80d1aca109aed263",
              "IPY_MODEL_c87caebcb0854dd9b7203dbaeb00f9c2",
              "IPY_MODEL_05deab3c24e8469c95888feabbbfa981"
            ],
            "layout": "IPY_MODEL_c2918207c0e940ff8a4ddd6985711dfc"
          }
        },
        "a6ef2de4cd0a49cf80d1aca109aed263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f38360feb440eab7d67dbcf639fd89",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c64501f22de84b78a745f7a0467acdda",
            "value": "â€‡â€‡0%"
          }
        },
        "c87caebcb0854dd9b7203dbaeb00f9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e222441ca934d9d8151e5f1596adc68",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_361fdd45a36f46d49f8cbb9bb77d30b2",
            "value": 0
          }
        },
        "05deab3c24e8469c95888feabbbfa981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40281ad4b6249939ac0daa1eb57190f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_08532770276e445cb2a7a591907166ff",
            "value": "â€‡0/75â€‡[00:00&lt;?,â€‡?it/s]"
          }
        },
        "c2918207c0e940ff8a4ddd6985711dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f38360feb440eab7d67dbcf639fd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c64501f22de84b78a745f7a0467acdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e222441ca934d9d8151e5f1596adc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361fdd45a36f46d49f8cbb9bb77d30b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e40281ad4b6249939ac0daa1eb57190f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08532770276e445cb2a7a591907166ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
